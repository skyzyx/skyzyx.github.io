{
    "data": {
        
        
        "count": 2,
        "items": [
            
            {
    "kind": "page",
    "title": "Running aws-vault in macOS with local Docker containers",
    "description": "",
    "summary": {
        "content": "Overview aws-vault is a tool for storing your AWS credentials in your system keychain instead of as a plain text file on-disk. Credentials and other secrets (including your various system passwords) are stored inside your system keychain. They are encrypted, and cannot easily be stolen by a rogue script or application. By keeping your AWS credentials in your system keychain, they are available to you when you are logged in, unavailable when you are logged out, and provide an important layer of security that the standard plain text storage method does not.",
        "isTruncated": true
    },
    "published": "2019-04-19T01:32:30Z",
    "updated": "2019-12-26T16:46:47-08:00",
    "permalink": "https://ryanparman.com/posts/2019/running-aws-vault-with-local-docker-containers/",
    "relativePermalink": "/posts/2019/running-aws-vault-with-local-docker-containers/",
    "aliases": ["/2019/04/19/running-aws-vault-with-local-docker-containers"],
    "images": ["https://cdn.ryanparman.com/hugo/posts/2019/secure-auth@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2019/keychain@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2019/generate-tokens@2x.png", "https://cdn.ryanparman.com/hugo/posts/2018/docker-logo.jpg"],
    "videos": [],
    "categories": ["Software"],
    "tags": ["99designs", "aws", "aws-cli", "aws-vault", "bash", "docker", "ec2", "elastic-beanstalk", "golang", "keychain", "mac", "macos", "parameter-store", "secrets", "session-tokens", "site-reliability-engineering", "sre"],
    "series": [],
    "keywords": [],
    "meta": {
        "wordCount": 896,
        "readingTime": "5 minutes",
        "language": "en",
        "isDraft": false,
        "isHome": false,
        "isNode": false,
        "isPage": true,
        "isTranslated": false
    },
    "sourceFile": {
        "path": "posts/2019/20190419-running-aws-vault-with-local-docker-containers.md",
        "logicalName": "20190419-running-aws-vault-with-local-docker-containers.md",
        "translationBaseName": "20190419-running-aws-vault-with-local-docker-containers",
        "baseFileName": "20190419-running-aws-vault-with-local-docker-containers",
        "ext": "md",
        "lang": "en",
        "dir": "posts/2019/"
    },
    "content": {
        "tableOfContents": "\u003cnav id=\"TableOfContents\"\u003e\n  \u003cul\u003e\n    \u003cli\u003e\u003ca href=\"#overview\"\u003eOverview\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#leveraging-the-keychain\"\u003eLeveraging the Keychain\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#aws-config-file\"\u003eAWS Config File\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#viewing-credentials\"\u003eViewing Credentials\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#token-types\"\u003eToken Types\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#passing-to-local-docker\"\u003ePassing to (local) Docker\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#conclusion\"\u003eConclusion\u003c/a\u003e\u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/nav\u003e",
        "html":"\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2019/secure-auth@2x.webp\" alt=\"Using aws-vault\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2019/secure-auth@2x.jpg\" alt=\"Using aws-vault\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://github.com/99designs/aws-vault\"\u003eaws-vault\u003c/a\u003e\u003c/strong\u003e is a tool for storing your AWS credentials in your system keychain instead of as a plain text file on-disk.\u003c/p\u003e\n\u003cp\u003eCredentials and other secrets (including your various system passwords) are stored inside your system keychain. They are encrypted, and cannot easily be stolen by a rogue script or application. By keeping your AWS credentials in your system keychain, they are available to you when you are logged in, unavailable when you are logged out, and provide an important layer of security that the standard plain text storage method does not.\u003c/p\u003e\n\u003cp\u003eIt is designed to work cooperatively with the \u003ca href=\"https://aws.amazon.com/cli/\"\u003eAWS Unified CLI Tools\u003c/a\u003e. It also provides utilities for other AWS best practices such as being able to generate session tokens, or logging into the AWS Console with your IAM credentials using a simple command.\u003c/p\u003e\n\u003cp\u003eYou can learn more about the thinking behind it from the \u003ca href=\"https://99designs.com.au/tech-blog/blog/2015/10/26/aws-vault/\"\u003eoriginal 99 designs blog post\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"leveraging-the-keychain\"\u003eLeveraging the Keychain\u003c/h2\u003e\n\u003cp\u003eBy default, every Mac user has a \u003cem\u003esystem\u003c/em\u003e and a \u003cem\u003elogin\u003c/em\u003e keychain that stores the bulk of your secure information (e.g., certificate authorities which enable SSL/TLS connections, website passwords or credit cards saved in your browser).\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2019/keychain@2x.webp\" alt=\"Leveraging the Keychain\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2019/keychain@2x.jpg\" alt=\"Leveraging the Keychain\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eOn macOS, credentials are stored in a non-\u003cem\u003elogin\u003c/em\u003e keychain in \u003cem\u003eKeychain Access.app\u003c/em\u003e. Instead, they are stored in a new \u003cem\u003eaws-vault\u003c/em\u003e keychain. In order to manage these credentials with the \u003cem\u003eKeychain Access.app\u003c/em\u003e app, you\u0026rsquo;ll need to import it.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eFile → Import Items…\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eChoose \u003ccode\u003eaws-vault.keychain-db\u003c/code\u003e from the default directory.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRight click → \u003cem\u003eChange Settings for Keychain “aws-vault”…\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eChange the value for \u003cem\u003eLock after {NUMBER} minutes of inactivity\u003c/em\u003e to something like 1440 minutes (1 day). Feel free to tune for security/convenience according to your tastes.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"aws-config-file\"\u003eAWS Config File\u003c/h2\u003e\n\u003cp\u003eAfter adding credentials to \u003ccode\u003eaws-vault\u003c/code\u003e (e.g., \u003ccode\u003eaws-vault add default\u003c/code\u003e), you can instruct the \u003ca href=\"https://aws.amazon.com/cli/\"\u003eaws-cli\u003c/a\u003e to use \u003ccode\u003eaws-vault\u003c/code\u003e instead of \u003ccode\u003e~/.aws/credentials\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eHere is an \u003ccode\u003e~/.aws/config\u003c/code\u003e entry for the \u003cem\u003edefault\u003c/em\u003e profile:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-ini\" data-lang=\"ini\"\u003e\u003cspan style=\"color:#66d9ef\"\u003e[default]\u003c/span\u003e\n\u003cspan style=\"color:#a6e22e\"\u003eregion\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003eus-east-1\u003c/span\u003e\n\u003cspan style=\"color:#a6e22e\"\u003ecredential_process\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003eaws-vault exec -j default\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAfter all credentials are stored in \u003ccode\u003eaws-vault\u003c/code\u003e, and all \u003ccode\u003e~/.aws/config\u003c/code\u003e entries have been updated with the \u003ccode\u003ecredential_process\u003c/code\u003e line, \u003ccode\u003e~/.aws/credentials\u003c/code\u003e should be \u003cstrong\u003eempty\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2 id=\"viewing-credentials\"\u003eViewing Credentials\u003c/h2\u003e\n\u003caside class=\"age aside container flex\"\u003e\n  \u003cp\u003emacOS ships with the FreeBSD flavor of command line tools instead of the GNU flavor which ships with most Linuxes. This post references the GNU flavor. Please see “\u003ca href=\"/posts/2019/using-gnu-command-line-tools-in-macos-instead-of-freebsd-tools/\"\u003eUsing GNU command line tools in macOS instead of FreeBSD tools\u003c/a\u003e” for more information.\u003c/p\u003e\n\u003c/aside\u003e\n\n\u003cp\u003eIf you want to view the credentials for a profile, or if you want to expose them as environment variables, you can run:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003eaws-vault exec default -- env | grep --no-color ^AWS | sort\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eIf you want to \u003cem\u003euse\u003c/em\u003e them, the \u003ca href=\"https://aws.amazon.com/cli/\"\u003eaws-cli\u003c/a\u003e will \u003ca href=\"https://docs.aws.amazon.com/cli/latest/topic/config-vars.html#id1\"\u003epick up environment variables before it looks for a credentials definition\u003c/a\u003e. So, if you want to use \u003ca href=\"https://github.com/99designs/aws-vault\"\u003eaws-vault\u003c/a\u003e with \u003ca href=\"https://aws.amazon.com/cli/\"\u003eaws-cli\u003c/a\u003e without specifying the \u003ccode\u003ecredential_process\u003c/code\u003e setting in your \u003ccode\u003e~/.aws/config\u003c/code\u003e entry, you can do something like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003eaws-vault exec default -- aws s3 ls\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"token-types\"\u003eToken Types\u003c/h2\u003e\n\u003cp\u003eThe AWS CLI (and any other tools built on AWS SDKs) will leverage the \u003ccode\u003eAWS_SESSION_TOKEN\u003c/code\u003e and \u003ccode\u003eAWS_SECURITY_TOKEN\u003c/code\u003e values before leveraging the \u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e and \u003ccode\u003eAWS_SECRET_ACCESS_KEY\u003c/code\u003e values.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eAWS_SESSION_TOKEN\u003c/code\u003e and \u003ccode\u003eAWS_SECURITY_TOKEN\u003c/code\u003e tokens are more secure because they are ephemeral, and expire after a short (measured in hours) TTL. For this reason, these should generally be used instead of the \u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e and \u003ccode\u003eAWS_SECRET_ACCESS_KEY\u003c/code\u003e values.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2019/generate-tokens@2x.webp\" alt=\"Generating Secure Tokens\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2019/generate-tokens@2x.png\" alt=\"Generating Secure Tokens\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003e\u003cstrong\u003eBut there is an exception\u003c/strong\u003e — there are certain types of IAM-related tasks which cannot be performed using \u003ccode\u003eAWS_SESSION_TOKEN\u003c/code\u003e and \u003ccode\u003eAWS_SECURITY_TOKEN\u003c/code\u003e tokens, because they are IAM tokens themselves. In these cases, you want to fall back to the long-lived \u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e and \u003ccode\u003eAWS_SECRET_ACCESS_KEY\u003c/code\u003e values. You can do this by passing the \u003ccode\u003e--no-session\u003c/code\u003e option to the \u003ccode\u003eaws-vault\u003c/code\u003e command.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003eaws-vault exec default --no-session -- env | grep --no-color ^AWS | sort\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eHere, you can see that the \u003ccode\u003eAWS_SESSION_TOKEN\u003c/code\u003e and \u003ccode\u003eAWS_SECURITY_TOKEN\u003c/code\u003e tokens are not generated, so the AWS CLI (and any other tools built on AWS SDKs) will leverage the \u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e and \u003ccode\u003eAWS_SECRET_ACCESS_KEY\u003c/code\u003e values instead.\u003c/p\u003e\n\u003ch2 id=\"passing-to-local-docker\"\u003ePassing to (local) Docker\u003c/h2\u003e\n\u003cp\u003eIt is becoming more popular to provide Docker containers for running software, especially when that software has a number of (potentially-complex) dependencies. By wrapping everything up into a nice little Docker image, it makes it much simpler to build and distribute software that is meant to run locally.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2018/docker-logo.webp\" alt=\"Docker Logo\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2018/docker-logo.jpg\" alt=\"Docker Logo\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eWith the traditional \u003ccode\u003e~/.aws\u003c/code\u003e directory, you can mount it as read-only inside a Docker container if you want that Docker container to be able to communicate with AWS on your behalf.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003edocker run -ti -v $HOME/.aws:/root/.aws:ro \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003eimage_name\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e sh\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eEasy, right? Wrap it in a \u003ccode\u003eMakefile\u003c/code\u003e or a Bash \u003ccode\u003ealias\u003c/code\u003e, and call it a day.\u003c/p\u003e\n\u003cp\u003eBut using \u003ccode\u003eaws-vault\u003c/code\u003e makes this a little more complicated. \u003ccode\u003eaws-vault\u003c/code\u003e runs on your local machine (not inside your Docker container), and your \u003ccode\u003e~/.aws/credentials\u003c/code\u003e file is empty. How do we pass your credentials into a Docker container?\u003c/p\u003e\n\u003cp\u003eBy exporting the environment variables and passing them to \u003ccode\u003edocker run\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003edocker run -ti \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    --env-file \u0026lt;\u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003eaws-vault exec default -- env | grep --no-color ^AWS_\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003eimage_name\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e sh\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003caside class=\"age aside container flex\"\u003e\n\u003cp\u003eTested in \u003cb\u003eBash 3.2.57\u003c/b\u003e (latest GPLv2 release; ships by default in macOS) + \u003cb\u003eBash 5.0.3\u003c/b\u003e (GPLv3; installed via Homebrew).\u003c/p\u003e\n\u003c/aside\u003e\n\n\u003cp\u003eWow! What does this do?\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eExports the credentials to the environment.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFilters the environment variables by those that begin with \u003ccode\u003eAWS\u003c/code\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRun Docker, passing the \u003ccode\u003eAWS_*\u003c/code\u003e environment variables into Docker.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThis particular command will start an interactive \u003ccode\u003esh\u003c/code\u003e shell session. You can run other commands using \u003ca href=\"https://docs.docker.com/engine/reference/commandline/run/\"\u003e\u003ccode\u003edocker run\u003c/code\u003e\u003c/a\u003e as appropriate.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/99designs/aws-vault\"\u003eaws-vault\u003c/a\u003e is a great tool for managing your credentials, helping you work with AWS-related tooling, and makes it easy to follow best-practices. If you\u0026rsquo;re interested in learning more, check out the \u003ccode\u003eREADME\u003c/code\u003e.\u003c/p\u003e\n",
        "plain":"  Overview aws-vault is a tool for storing your AWS credentials in your system keychain instead of as a plain text file on-disk.\nCredentials and other secrets (including your various system passwords) are stored inside your system keychain. They are encrypted, and cannot easily be stolen by a rogue script or application. By keeping your AWS credentials in your system keychain, they are available to you when you are logged in, unavailable when you are logged out, and provide an important layer of security that the standard plain text storage method does not.\nIt is designed to work cooperatively with the AWS Unified CLI Tools. It also provides utilities for other AWS best practices such as being able to generate session tokens, or logging into the AWS Console with your IAM credentials using a simple command.\nYou can learn more about the thinking behind it from the original 99 designs blog post.\nLeveraging the Keychain By default, every Mac user has a system and a login keychain that stores the bulk of your secure information (e.g., certificate authorities which enable SSL/TLS connections, website passwords or credit cards saved in your browser).\n  On macOS, credentials are stored in a non-login keychain in Keychain Access.app. Instead, they are stored in a new aws-vault keychain. In order to manage these credentials with the Keychain Access.app app, you\u0026rsquo;ll need to import it.\n  File → Import Items…\n  Choose aws-vault.keychain-db from the default directory.\n  Right click → Change Settings for Keychain “aws-vault”…\n  Change the value for Lock after {NUMBER} minutes of inactivity to something like 1440 minutes (1 day). Feel free to tune for security/convenience according to your tastes.\n  AWS Config File After adding credentials to aws-vault (e.g., aws-vault add default), you can instruct the aws-cli to use aws-vault instead of ~/.aws/credentials.\nHere is an ~/.aws/config entry for the default profile:\n[default] region=us-east-1 credential_process=aws-vault exec -j default After all credentials are stored in aws-vault, and all ~/.aws/config entries have been updated with the credential_process line, ~/.aws/credentials should be empty.\nViewing Credentials macOS ships with the FreeBSD flavor of command line tools instead of the GNU flavor which ships with most Linuxes. This post references the GNU flavor. Please see “Using GNU command line tools in macOS instead of FreeBSD tools” for more information.\n If you want to view the credentials for a profile, or if you want to expose them as environment variables, you can run:\naws-vault exec default -- env | grep --no-color ^AWS | sort If you want to use them, the aws-cli will pick up environment variables before it looks for a credentials definition. So, if you want to use aws-vault with aws-cli without specifying the credential_process setting in your ~/.aws/config entry, you can do something like this:\naws-vault exec default -- aws s3 ls Token Types The AWS CLI (and any other tools built on AWS SDKs) will leverage the AWS_SESSION_TOKEN and AWS_SECURITY_TOKEN values before leveraging the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY values.\nAWS_SESSION_TOKEN and AWS_SECURITY_TOKEN tokens are more secure because they are ephemeral, and expire after a short (measured in hours) TTL. For this reason, these should generally be used instead of the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY values.\n  But there is an exception — there are certain types of IAM-related tasks which cannot be performed using AWS_SESSION_TOKEN and AWS_SECURITY_TOKEN tokens, because they are IAM tokens themselves. In these cases, you want to fall back to the long-lived AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY values. You can do this by passing the --no-session option to the aws-vault command.\naws-vault exec default --no-session -- env | grep --no-color ^AWS | sort Here, you can see that the AWS_SESSION_TOKEN and AWS_SECURITY_TOKEN tokens are not generated, so the AWS CLI (and any other tools built on AWS SDKs) will leverage the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY values instead.\nPassing to (local) Docker It is becoming more popular to provide Docker containers for running software, especially when that software has a number of (potentially-complex) dependencies. By wrapping everything up into a nice little Docker image, it makes it much simpler to build and distribute software that is meant to run locally.\n  With the traditional ~/.aws directory, you can mount it as read-only inside a Docker container if you want that Docker container to be able to communicate with AWS on your behalf.\ndocker run -ti -v $HOME/.aws:/root/.aws:ro {image_name} sh Easy, right? Wrap it in a Makefile or a Bash alias, and call it a day.\nBut using aws-vault makes this a little more complicated. aws-vault runs on your local machine (not inside your Docker container), and your ~/.aws/credentials file is empty. How do we pass your credentials into a Docker container?\nBy exporting the environment variables and passing them to docker run.\ndocker run -ti \\  --env-file \u0026lt;(aws-vault exec default -- env | grep --no-color ^AWS_) \\  {image_name} sh  Tested in Bash 3.2.57 (latest GPLv2 release; ships by default in macOS) + Bash 5.0.3 (GPLv3; installed via Homebrew).\n Wow! What does this do?\n  Exports the credentials to the environment.\n  Filters the environment variables by those that begin with AWS.\n  Run Docker, passing the AWS_* environment variables into Docker.\n  This particular command will start an interactive sh shell session. You can run other commands using docker run as appropriate.\n  Conclusion aws-vault is a great tool for managing your credentials, helping you work with AWS-related tooling, and makes it easy to follow best-practices. If you\u0026rsquo;re interested in learning more, check out the README.\n",
        "source":"\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2019/secure-auth@2x.jpg\" alt=\"Using aws-vault\" width=\"2000\" height=\"873\" \u003e}}\n\n## Overview\n\n**[aws-vault]** is a tool for storing your AWS credentials in your system keychain instead of as a plain text file on-disk.\n\nCredentials and other secrets (including your various system passwords) are stored inside your system keychain. They are encrypted, and cannot easily be stolen by a rogue script or application. By keeping your AWS credentials in your system keychain, they are available to you when you are logged in, unavailable when you are logged out, and provide an important layer of security that the standard plain text storage method does not.\n\nIt is designed to work cooperatively with the [AWS Unified CLI Tools][aws-cli]. It also provides utilities for other AWS best practices such as being able to generate session tokens, or logging into the AWS Console with your IAM credentials using a simple command.\n\nYou can learn more about the thinking behind it from the [original 99 designs blog post]({{\u003c wayback \"https://99designs.com.au/tech-blog/blog/2015/10/26/aws-vault/\" \u003e}}).\n\n## Leveraging the Keychain\n\nBy default, every Mac user has a _system_ and a _login_ keychain that stores the bulk of your secure information (e.g., certificate authorities which enable SSL/TLS connections, website passwords or credit cards saved in your browser).\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2019/keychain@2x.jpg\" alt=\"Leveraging the Keychain\" width=\"1920\" height=\"1080\" \u003e}}\n\nOn macOS, credentials are stored in a non-_login_ keychain in _Keychain Access.app_. Instead, they are stored in a new _aws-vault_ keychain. In order to manage these credentials with the _Keychain Access.app_ app, you'll need to import it.\n\n1. _File → Import Items…_\n\n1. Choose `aws-vault.keychain-db` from the default directory.\n\n1. Right click → _Change Settings for Keychain “aws-vault”…_\n\n1. Change the value for _Lock after {NUMBER} minutes of inactivity_ to something like 1440 minutes (1 day). Feel free to tune for security/convenience according to your tastes.\n\n## AWS Config File\n\nAfter adding credentials to `aws-vault` (e.g., `aws-vault add default`), you can instruct the [aws-cli] to use `aws-vault` instead of `~/.aws/credentials`.\n\nHere is an `~/.aws/config` entry for the _default_ profile:\n\n```ini\n[default]\nregion=us-east-1\ncredential_process=aws-vault exec -j default\n```\n\nAfter all credentials are stored in `aws-vault`, and all `~/.aws/config` entries have been updated with the `credential_process` line, `~/.aws/credentials` should be **empty**.\n\n## Viewing Credentials\n\n{{\u003cmac-gnu\u003e}}\n\nIf you want to view the credentials for a profile, or if you want to expose them as environment variables, you can run:\n\n```bash\naws-vault exec default -- env | grep --no-color ^AWS | sort\n```\n\nIf you want to _use_ them, the [aws-cli] will [pick up environment variables before it looks for a credentials definition](https://docs.aws.amazon.com/cli/latest/topic/config-vars.html#id1). So, if you want to use [aws-vault] with [aws-cli] without specifying the `credential_process` setting in your `~/.aws/config` entry, you can do something like this:\n\n```bash\naws-vault exec default -- aws s3 ls\n```\n\n## Token Types\n\nThe AWS CLI (and any other tools built on AWS SDKs) will leverage the `AWS_SESSION_TOKEN` and `AWS_SECURITY_TOKEN` values before leveraging the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` values.\n\n`AWS_SESSION_TOKEN` and `AWS_SECURITY_TOKEN` tokens are more secure because they are ephemeral, and expire after a short (measured in hours) TTL. For this reason, these should generally be used instead of the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` values.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2019/generate-tokens@2x.png\" alt=\"Generating Secure Tokens\" width=\"2000\" height=\"874\" \u003e}}\n\n**But there is an exception** — there are certain types of IAM-related tasks which cannot be performed using `AWS_SESSION_TOKEN` and `AWS_SECURITY_TOKEN` tokens, because they are IAM tokens themselves. In these cases, you want to fall back to the long-lived `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` values. You can do this by passing the `--no-session` option to the `aws-vault` command.\n\n```bash\naws-vault exec default --no-session -- env | grep --no-color ^AWS | sort\n```\n\nHere, you can see that the `AWS_SESSION_TOKEN` and `AWS_SECURITY_TOKEN` tokens are not generated, so the AWS CLI (and any other tools built on AWS SDKs) will leverage the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` values instead.\n\n## Passing to (local) Docker\n\nIt is becoming more popular to provide Docker containers for running software, especially when that software has a number of (potentially-complex) dependencies. By wrapping everything up into a nice little Docker image, it makes it much simpler to build and distribute software that is meant to run locally.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/docker-logo.jpg\" alt=\"Docker Logo\" width=\"2400\" height=\"1048\" \u003e}}\n\nWith the traditional `~/.aws` directory, you can mount it as read-only inside a Docker container if you want that Docker container to be able to communicate with AWS on your behalf.\n\n```bash\ndocker run -ti -v $HOME/.aws:/root/.aws:ro {image_name} sh\n```\n\nEasy, right? Wrap it in a `Makefile` or a Bash `alias`, and call it a day.\n\nBut using `aws-vault` makes this a little more complicated. `aws-vault` runs on your local machine (not inside your Docker container), and your `~/.aws/credentials` file is empty. How do we pass your credentials into a Docker container?\n\nBy exporting the environment variables and passing them to `docker run`.\n\n```bash\ndocker run -ti \\\n    --env-file \u003c(aws-vault exec default -- env | grep --no-color ^AWS_) \\\n    {image_name} sh\n```\n\n{{\u003caside\u003e}}\n\u003cp\u003eTested in \u003cb\u003eBash 3.2.57\u003c/b\u003e (latest GPLv2 release; ships by default in macOS) + \u003cb\u003eBash 5.0.3\u003c/b\u003e (GPLv3; installed via Homebrew).\u003c/p\u003e\n{{\u003c/aside\u003e}}\n\nWow! What does this do?\n\n1. Exports the credentials to the environment.\n\n1. Filters the environment variables by those that begin with `AWS`.\n\n1. Run Docker, passing the `AWS_*` environment variables into Docker.\n\n1. This particular command will start an interactive `sh` shell session. You can run other commands using [`docker run`](https://docs.docker.com/engine/reference/commandline/run/) as appropriate.\n\n## Conclusion\n\n[aws-vault] is a great tool for managing your credentials, helping you work with AWS-related tooling, and makes it easy to follow best-practices. If you're interested in learning more, check out the `README`.\n\n  [aws-cli]: https://aws.amazon.com/cli/\n  [aws-vault]: https://github.com/99designs/aws-vault\n"},
    "links": {
        "prev": {"title": "Converting iMessage Stickers, Animoji, and Memoji to Slackmoji (Slack Emoji)", "permalink": "https://ryanparman.com/posts/2019/converting-imessage-stickers-animoji-and-memoji-to-slackmoji-slack-emoji/"},
        "next": {"title": "Using GNU command line tools in macOS instead of FreeBSD tools", "permalink": "https://ryanparman.com/posts/2019/using-gnu-command-line-tools-in-macos-instead-of-freebsd-tools/"},
        "ignore": "me"
    }
}

            
            , {
    "kind": "page",
    "title": "Understanding Trust in Your Infrastructure",
    "description": "Trust should be earned, not given blindly.",
    "summary": {
        "content": "Only a tiny fraction of the code your application runs was written by you or your team. How do you know you can trust the code that was written by other people? Where would you even start? This piece is part of a larger series on Engineering for Site Reliability, specifically balancing stability against the edge of technology. What do I mean by \u0026ldquo;trust\u0026rdquo;? Movies and TV shows have given us a version of trust which essentially boils down to “Do you trust me?",
        "isTruncated": true
    },
    "published": "2018-12-27T07:30:30Z",
    "updated": "2019-02-10T21:35:12-08:00",
    "permalink": "https://ryanparman.com/posts/2018/understanding-trust-in-your-infrastructure/",
    "relativePermalink": "/posts/2018/understanding-trust-in-your-infrastructure/",
    "aliases": ["/2018/12/27/understanding-trust-in-your-infrastructure"],
    "images": ["https://cdn.ryanparman.com/hugo/posts/2018/trust-dial@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/broken-collarbone@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/teen-titans@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/wrong-way@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/etc-passwd@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/batman-slap-docker-dev@2x.jpg", "https://cdn.ryanparman.com/hugo/headers/understanding-trust/severed-wrists@2x.jpg"],
    "videos": [],
    "categories": ["Engineering for Site Reliability"],
    "tags": ["trust", "docker", "alpine linux", "centos", "ubuntu", "rhel", "php", "python", "nodejs", "golang", "nginx", "composer", "pip", "npm", "java", "cve", "security", "site reliability engineering"],
    "series": ["Engineering for Site Reliability"],
    "keywords": [],
    "meta": {
        "wordCount": 1608,
        "readingTime": "8 minutes",
        "language": "en",
        "isDraft": false,
        "isHome": false,
        "isNode": false,
        "isPage": true,
        "isTranslated": false
    },
    "sourceFile": {
        "path": "posts/2018/20181227-understanding-trust-in-your-infrastructure.md",
        "logicalName": "20181227-understanding-trust-in-your-infrastructure.md",
        "translationBaseName": "20181227-understanding-trust-in-your-infrastructure",
        "baseFileName": "20181227-understanding-trust-in-your-infrastructure",
        "ext": "md",
        "lang": "en",
        "dir": "posts/2018/"
    },
    "content": {
        "tableOfContents": "\u003cnav id=\"TableOfContents\"\u003e\n  \u003cul\u003e\n    \u003cli\u003e\u003ca href=\"#what-do-i-mean-by-trust\"\u003eWhat do I mean by \u0026ldquo;trust\u0026rdquo;?\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#what-is-my-application\"\u003eWhat is my application?\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#reusable-layers-and-understanding-trust\"\u003eReusable layers, and understanding trust\u003c/a\u003e\n      \u003cul\u003e\n        \u003cli\u003e\u003ca href=\"#an-unpublished-package-broke-the-internet\"\u003eAn unpublished package broke the internet\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#crashing-the-entire-stack\"\u003eCrashing the entire stack\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#devprod-parity\"\u003eDev/Prod parity\u003c/a\u003e\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#guidelines-for-trust\"\u003eGuidelines for trust\u003c/a\u003e\u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/nav\u003e",
        "html":"\u003cp itemprop=\"description\" class=\"f5 f4-m f3-l mt0 lh-copy p-summary entry-summary\"\u003e\nOnly a tiny fraction of the code your application runs was written by you or your team. How do you know you can trust the code that was written by other people? Where would you even start?\n\u003c/p\u003e\n\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2018/trust-dial@2x.webp\" alt=\"Trust dial\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2018/trust-dial@2x.jpg\" alt=\"Trust dial\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\n\u003caside class=\"age aside container flex\"\u003e\u003cp\u003eThis piece is part of a larger series on \u003ca href=\"/series/engineering-for-site-reliability/\"\u003eEngineering for Site Reliability\u003c/a\u003e, specifically \u003cem\u003ebalancing stability against the edge of technology\u003c/em\u003e.\u003c/p\u003e\n\u003c/aside\u003e\n\n\u003ch2 id=\"what-do-i-mean-by-trust\"\u003eWhat do I mean by \u0026ldquo;trust\u0026rdquo;?\u003c/h2\u003e\n\u003cp\u003eMovies and TV shows have given us a version of trust which essentially boils down to “Do you trust me?” as they hold out their hand to another person. In the movies things generally work out in the end, even if they run into a little more trouble along the way. This is the kind of trust that teenagers, newly in-love, have with their new person.\u003c/p\u003e\n\u003cp\u003eThis is also the kind of trust that most engineers have in their software dependencies. \u003cstrong\u003eThis is not what trust is\u003c/strong\u003e, and is a \u003cstrong\u003ehigh-risk\u003c/strong\u003e way to build applications.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2018/teen-titans@2x.webp\" alt=\"Teen Titans\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2018/teen-titans@2x.jpg\" alt=\"Teen Titans\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eIf you\u0026rsquo;ve ever been spurned by an ex-lover, or have grown-up around shady people, you\u0026rsquo;ll likely have a different definition of trust. A marriage counselor may say something like \u0026ldquo;trust, but verify\u0026rdquo;. A person who has grown-up in a bad neighborhood or around shady people may have the perspective that \u003cem\u003etrust is earned, not given\u003c/em\u003e. \u003cstrong\u003eA certain amount of paranoia is a good thing\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eHowever, as with everything, you can also have too much paranoia. These are the teams who ship an application, and if it\u0026rsquo;s not broken, they don\u0026rsquo;t touch it. Their curse is that they fall so far behind the security and maintenance curves, that their applications become ticking time bombs — defeating the very purpose they think their paranoia addresses.\u003c/p\u003e\n\u003cp\u003eThe point that I\u0026rsquo;d like you to take away from this is that \u003cem\u003etrust is earned, not given\u003c/em\u003e. When you come from this perspective, you make better technical decisions.\u003c/p\u003e\n\u003ch2 id=\"what-is-my-application\"\u003eWhat is my application?\u003c/h2\u003e\n\u003cp\u003eDepending on the type of engineer you are (front-end, backend, ops), you may look at the applications you work on through different lenses.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSome see the client-side, browser code they\u0026rsquo;re writing.\u003c/li\u003e\n\u003cli\u003eSome see the Golang, Node.js, Python, or PHP code they\u0026rsquo;re writing.\u003c/li\u003e\n\u003cli\u003eSome see the package dependencies, and their package dependencies, and so on…\u003c/li\u003e\n\u003cli\u003eSome see code like the Docker runtime, OpenSSL, cURL, or the Linux kernel.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn truth, \u003cem\u003eall of these answers are correct\u003c/em\u003e. The best engineers know how important it is to look at the entire stack — from the application, to the runtime, to the hypervisor, to the kernel.\u003c/p\u003e\n\u003ch2 id=\"reusable-layers-and-understanding-trust\"\u003eReusable layers, and understanding trust\u003c/h2\u003e\n\u003cp\u003eIt\u0026rsquo;s a common (and extremely sensible) pattern to re-use and build atop existing technology layers. By leveraging this powerful foundation, we can build bigger, better, and more powerful appications and services! But we also need to understand how core concepts like \u003cem\u003etrust\u003c/em\u003e work between all of these layers.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2018/wrong-way@2x.webp\" alt=\"Wrong way sign\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2018/wrong-way@2x.jpg\" alt=\"Wrong way sign\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eLet me give a few examples of anti-patterns that are also very commonplace in many organizations (mostly due to ignorance, as opposed to malice):\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eNOTE:\u003c/strong\u003e I\u0026rsquo;m speaking from a context of applications which run on popular cloud infrastructure services like AWS, GCP, or Azure, and have sane processes in place like actively-supported system images (e.g., AMIs).\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eFetching application dependencies \u003cem\u003elive\u003c/em\u003e from upstream sources (e.g., the internet is ephemeral; is your app?).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRunning package manager updates when spinning-up a new machine (e.g., modifying the underlying system image at boot-time; \u003ccode\u003eyum -y update\u003c/code\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRunning package manager updates when deploying to Production (e.g., picking up potentially untested software without a testing stage in-between).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAdding new package manager repositories from random places on the internet (e.g., taking candy from strangers).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRelying exclusively on a single \u003cem\u003eavailability zone\u003c/em\u003e or \u003cem\u003eregion\u003c/em\u003e from their cloud infrastructure provider.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e“These aren’t anti-patterns,” you say. “They’re just how development is done.”\u003c/p\u003e\n\u003cp\u003eThank you for your thoughts, hypothetical reader. But consider the following:\u003c/p\u003e\n\u003ch3 id=\"an-unpublished-package-broke-the-internet\"\u003eAn unpublished package broke the internet\u003c/h3\u003e\n\u003cp\u003eIn case you forgot, in early 2016, \u003cem\u003eone package\u003c/em\u003e \u003ca href=\"https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm\"\u003ebroke the entire Node.js ecosystem\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2018/broken-collarbone@2x.webp\" alt=\"Broken collarbone\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2018/broken-collarbone@2x.jpg\" alt=\"Broken collarbone\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eDavid Haney writes in his piece “\u003ca href=\"https://www.davidhaney.io/npm-left-pad-have-we-forgotten-how-to-program/\"\u003eNPM \u0026amp; left-pad: Have We Forgotten How To Program?\u003c/a\u003e”:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eOkay developers, time to have a serious talk. As you are probably already aware, this week React, Babel, and a bunch of other high-profile packages on NPM broke. The reason they broke is rather astounding:\u003c/p\u003e\n\u003cp\u003eA simple NPM package called \u003cem\u003eleft-pad\u003c/em\u003e that was a dependency of their code.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eleft-pad\u003c/em\u003e, at the time of writing this, has 11 stars on GitHub. The entire package is 11 simple lines that implement a basic left-pad string function. […]\u003c/p\u003e\n\u003cp\u003eWhat concerns me here is that \u003cem\u003eso many packages and projects\u003c/em\u003e took on a \u003cstrong\u003edependency\u003c/strong\u003e for a simple left padding string function, rather than their developers taking 2 minutes to write such a basic function themselves.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eEach and every application team which was hit by this issue, and allowed it to impact a Production-facing deployment, \u003cstrong\u003efailed to understand trust\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eIn this case, they should have implemented a \u003cem\u003epackage caching system\u003c/em\u003e, which can fetch a dependency on the first request, then cache that version for all subsequent requests. That way, if there is an issue with an upstream source, you will not be impacted.\u003c/p\u003e\n\u003ch3 id=\"crashing-the-entire-stack\"\u003eCrashing the entire stack\u003c/h3\u003e\n\u003cp\u003eI was working at Amazon Web Services back in 2010 when \u003ca href=\"https://aws.amazon.com/elasticbeanstalk/\"\u003eAWS Elastic Beanstalk\u003c/a\u003e was still in development. The team was working to build an easy-to-use solution around the idea of \u0026ldquo;application containers\u0026rdquo; (back before Docker was spun-out from \u003ca href=\"https://www.crunchbase.com/organization/dotcloud\"\u003edotCloud\u003c/a\u003e, an early PaaS provider). At the time I was helping them add PHP + Apache support to Elastic Beanstalk in time for launch, as I was the \u003cem\u003ede-facto\u003c/em\u003e “PHP guy” in AWS.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2018/etc-passwd@2x.webp\" alt=\"/etc/passwd\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2018/etc-passwd@2x.jpg\" alt=\"/etc/passwd\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eDevelopment was running on a pre-release version of what would become \u003ca href=\"https://aws.amazon.com/amazon-linux-ami/\"\u003eAmazon Linux\u003c/a\u003e. The original configuration was designed to run \u003ccode\u003eyum -y update\u003c/code\u003e on boot, which essentially means \u003cem\u003epick up the latest versions of all installed packages\u003c/em\u003e. While the team was thinking about system security (and avoiding outdated packages), everything broke on the day that the Amazon Linux team published a new version of Apache with backwards-incompatible changes. The development team \u003cstrong\u003efailed to understand trust\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eFortunately, it was a little before the public launch, and so only a few internal beta customers and developers were impacted. But watching that incident was the day that I learned that you don\u0026rsquo;t \u003cem\u003earbitrarily\u003c/em\u003e install all system updates. You should do that in your development environment instead, work out the issues, then roll something out to Production that has been tested and works as expected.\u003c/p\u003e\n\u003ch3 id=\"devprod-parity\"\u003eDev/Prod parity\u003c/h3\u003e\n\u003cp\u003eIf you\u0026rsquo;ve never heard of the \u003ca href=\"https://www.12factor.net\"\u003e12-factor app methodology\u003c/a\u003e, you are absolutely missing out. One of the chapters is entitled “\u003ca href=\"https://www.12factor.net/dev-prod-parity\"\u003eDev/prod parity\u003c/a\u003e”, which essentially boils down to \u003cem\u003ekeeping development, staging, and production as similar as possible\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eOne thing that I\u0026rsquo;ve seen bite a team is that they were deploying an application by pushing the source code from Git to the production instances, then resolving their packages \u003cem\u003edirectly on the instance\u003c/em\u003e. (To be fair, this was back in the days when \u003ca href=\"https://capistranorb.com\"\u003eCapistrano\u003c/a\u003e was hot, and we\u0026rsquo;ve come a long way since then.)\u003c/p\u003e\n\u003cp\u003eBut even in the world of Docker and \u003cem\u003econtinuous integration\u003c/em\u003e, I still see similar things happen. A team will build a Docker image for their dev app in their CI pipeline, push it to their Docker repository, then deploy it to dev. Then they build the image again when deploying to staging. Then again when they deploy to Prod. \u003cstrong\u003eThis is the same problem!\u003c/strong\u003e The dependencies are not being tested appropriately in the earlier environments before progressing to the production environment.\u003c/p\u003e\n\u003cp\u003eWith Docker, some teams have figured out how to make the exact same mistakes even faster! Those teams have \u003cstrong\u003efailed to understand trust\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eInstead, you should build the production-ready Docker image \u003cem\u003eonce\u003c/em\u003e, then promote that same image up to each environment as the requisite confidence is built.\u003c/p\u003e\n\u003cp\u003e“But how do I include my development dependencies inside my Docker container?”\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2018/batman-slap-docker-dev@2x.webp\" alt=\"Batman slaps Robin\" class=\"db fullimage\" decoding=\"async\"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2018/batman-slap-docker-dev@2x.jpg\" alt=\"Batman slaps Robin\" class=\"db fullimage\" decoding=\"async\"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eDocker images that are built should be the exact same bytes, regardless of the environment. Your dev build should write out logs in the same way as your Production app would (although perhaps to a local location). You should be able to define things like environment variables that are read by the Docker daemon at container launch. Or by defining a local volume to mount containing configuration information. But the insides of the Docker image should always be completely identical between environments.\u003c/p\u003e\n\u003ch2 id=\"guidelines-for-trust\"\u003eGuidelines for trust\u003c/h2\u003e\n\u003cp\u003eWhen you\u0026rsquo;re provisioning software onto a machine that will run in Production, you don\u0026rsquo;t want to be running software from \u003cem\u003eanywhere\u003c/em\u003e. You need to know that you can \u003cem\u003etrust\u003c/em\u003e the source of the software before you ship it into Production.\u003c/p\u003e\n\u003cp\u003eIn my case, I tend to work on teams which run servers with a blend of RedHat Enterprise Linux (RHEL), CentOS, and Amazon Linux. Containers are commonly Ubuntu, Debian, or Alpine. I work with applications written in nearly every major programming language. These are my criteria for determining whether or not to trust a package or Docker image.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ePackages are maintained by CentOS, RedHat, Amazon, Ubuntu, Debian, Alpine, etc., directly.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePackages are maintained by the vendor of the software directly (e.g., Docker, Amazon, PHP, Node Foundation, Angular, Kubernetes).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePackages are maintained by a reputable third-party source (as few of these as possible; e.g., \u003ca href=\"https://github.com/nodesource/distributions\"\u003eNodeSource\u003c/a\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePackages are maintained by us. That is, we compile them from source ourselves (into \u003ccode\u003e.rpm\u003c/code\u003e, \u003ccode\u003e.deb\u003c/code\u003e, or \u003ccode\u003e.apk\u003c/code\u003e packages), or we write the software packages ourselves (e.g., \u003ccode\u003ecomposer\u003c/code\u003e, \u003ccode\u003epip\u003c/code\u003e, \u003ccode\u003enpm\u003c/code\u003e, \u003ccode\u003edep\u003c/code\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eYour criteria may look different, and that\u0026rsquo;s OK. Some engineering teams are better at this, while others are still maturing.\u003c/p\u003e\n\u003cp\u003eIf you don\u0026rsquo;t have criteria, and generally just install software from anywhere, I have two pieces of advice.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eStop it.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOur criteria has been very good to us. Feel free to borrow ours.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n",
        "plain":"Only a tiny fraction of the code your application runs was written by you or your team. How do you know you can trust the code that was written by other people? Where would you even start?   This piece is part of a larger series on Engineering for Site Reliability, specifically balancing stability against the edge of technology.\n What do I mean by \u0026ldquo;trust\u0026rdquo;? Movies and TV shows have given us a version of trust which essentially boils down to “Do you trust me?” as they hold out their hand to another person. In the movies things generally work out in the end, even if they run into a little more trouble along the way. This is the kind of trust that teenagers, newly in-love, have with their new person.\nThis is also the kind of trust that most engineers have in their software dependencies. This is not what trust is, and is a high-risk way to build applications.\n  If you\u0026rsquo;ve ever been spurned by an ex-lover, or have grown-up around shady people, you\u0026rsquo;ll likely have a different definition of trust. A marriage counselor may say something like \u0026ldquo;trust, but verify\u0026rdquo;. A person who has grown-up in a bad neighborhood or around shady people may have the perspective that trust is earned, not given. A certain amount of paranoia is a good thing.\nHowever, as with everything, you can also have too much paranoia. These are the teams who ship an application, and if it\u0026rsquo;s not broken, they don\u0026rsquo;t touch it. Their curse is that they fall so far behind the security and maintenance curves, that their applications become ticking time bombs — defeating the very purpose they think their paranoia addresses.\nThe point that I\u0026rsquo;d like you to take away from this is that trust is earned, not given. When you come from this perspective, you make better technical decisions.\nWhat is my application? Depending on the type of engineer you are (front-end, backend, ops), you may look at the applications you work on through different lenses.\n Some see the client-side, browser code they\u0026rsquo;re writing. Some see the Golang, Node.js, Python, or PHP code they\u0026rsquo;re writing. Some see the package dependencies, and their package dependencies, and so on… Some see code like the Docker runtime, OpenSSL, cURL, or the Linux kernel.  In truth, all of these answers are correct. The best engineers know how important it is to look at the entire stack — from the application, to the runtime, to the hypervisor, to the kernel.\nReusable layers, and understanding trust It\u0026rsquo;s a common (and extremely sensible) pattern to re-use and build atop existing technology layers. By leveraging this powerful foundation, we can build bigger, better, and more powerful appications and services! But we also need to understand how core concepts like trust work between all of these layers.\n  Let me give a few examples of anti-patterns that are also very commonplace in many organizations (mostly due to ignorance, as opposed to malice):\n NOTE: I\u0026rsquo;m speaking from a context of applications which run on popular cloud infrastructure services like AWS, GCP, or Azure, and have sane processes in place like actively-supported system images (e.g., AMIs).\n   Fetching application dependencies live from upstream sources (e.g., the internet is ephemeral; is your app?).\n  Running package manager updates when spinning-up a new machine (e.g., modifying the underlying system image at boot-time; yum -y update).\n  Running package manager updates when deploying to Production (e.g., picking up potentially untested software without a testing stage in-between).\n  Adding new package manager repositories from random places on the internet (e.g., taking candy from strangers).\n  Relying exclusively on a single availability zone or region from their cloud infrastructure provider.\n  “These aren’t anti-patterns,” you say. “They’re just how development is done.”\nThank you for your thoughts, hypothetical reader. But consider the following:\nAn unpublished package broke the internet In case you forgot, in early 2016, one package broke the entire Node.js ecosystem.\n  David Haney writes in his piece “NPM \u0026amp; left-pad: Have We Forgotten How To Program?”:\n Okay developers, time to have a serious talk. As you are probably already aware, this week React, Babel, and a bunch of other high-profile packages on NPM broke. The reason they broke is rather astounding:\nA simple NPM package called left-pad that was a dependency of their code.\nleft-pad, at the time of writing this, has 11 stars on GitHub. The entire package is 11 simple lines that implement a basic left-pad string function. […]\nWhat concerns me here is that so many packages and projects took on a dependency for a simple left padding string function, rather than their developers taking 2 minutes to write such a basic function themselves.\n Each and every application team which was hit by this issue, and allowed it to impact a Production-facing deployment, failed to understand trust.\nIn this case, they should have implemented a package caching system, which can fetch a dependency on the first request, then cache that version for all subsequent requests. That way, if there is an issue with an upstream source, you will not be impacted.\nCrashing the entire stack I was working at Amazon Web Services back in 2010 when AWS Elastic Beanstalk was still in development. The team was working to build an easy-to-use solution around the idea of \u0026ldquo;application containers\u0026rdquo; (back before Docker was spun-out from dotCloud, an early PaaS provider). At the time I was helping them add PHP + Apache support to Elastic Beanstalk in time for launch, as I was the de-facto “PHP guy” in AWS.\n  Development was running on a pre-release version of what would become Amazon Linux. The original configuration was designed to run yum -y update on boot, which essentially means pick up the latest versions of all installed packages. While the team was thinking about system security (and avoiding outdated packages), everything broke on the day that the Amazon Linux team published a new version of Apache with backwards-incompatible changes. The development team failed to understand trust.\nFortunately, it was a little before the public launch, and so only a few internal beta customers and developers were impacted. But watching that incident was the day that I learned that you don\u0026rsquo;t arbitrarily install all system updates. You should do that in your development environment instead, work out the issues, then roll something out to Production that has been tested and works as expected.\nDev/Prod parity If you\u0026rsquo;ve never heard of the 12-factor app methodology, you are absolutely missing out. One of the chapters is entitled “Dev/prod parity”, which essentially boils down to keeping development, staging, and production as similar as possible.\nOne thing that I\u0026rsquo;ve seen bite a team is that they were deploying an application by pushing the source code from Git to the production instances, then resolving their packages directly on the instance. (To be fair, this was back in the days when Capistrano was hot, and we\u0026rsquo;ve come a long way since then.)\nBut even in the world of Docker and continuous integration, I still see similar things happen. A team will build a Docker image for their dev app in their CI pipeline, push it to their Docker repository, then deploy it to dev. Then they build the image again when deploying to staging. Then again when they deploy to Prod. This is the same problem! The dependencies are not being tested appropriately in the earlier environments before progressing to the production environment.\nWith Docker, some teams have figured out how to make the exact same mistakes even faster! Those teams have failed to understand trust.\nInstead, you should build the production-ready Docker image once, then promote that same image up to each environment as the requisite confidence is built.\n“But how do I include my development dependencies inside my Docker container?”\n  Docker images that are built should be the exact same bytes, regardless of the environment. Your dev build should write out logs in the same way as your Production app would (although perhaps to a local location). You should be able to define things like environment variables that are read by the Docker daemon at container launch. Or by defining a local volume to mount containing configuration information. But the insides of the Docker image should always be completely identical between environments.\nGuidelines for trust When you\u0026rsquo;re provisioning software onto a machine that will run in Production, you don\u0026rsquo;t want to be running software from anywhere. You need to know that you can trust the source of the software before you ship it into Production.\nIn my case, I tend to work on teams which run servers with a blend of RedHat Enterprise Linux (RHEL), CentOS, and Amazon Linux. Containers are commonly Ubuntu, Debian, or Alpine. I work with applications written in nearly every major programming language. These are my criteria for determining whether or not to trust a package or Docker image.\n  Packages are maintained by CentOS, RedHat, Amazon, Ubuntu, Debian, Alpine, etc., directly.\n  Packages are maintained by the vendor of the software directly (e.g., Docker, Amazon, PHP, Node Foundation, Angular, Kubernetes).\n  Packages are maintained by a reputable third-party source (as few of these as possible; e.g., NodeSource).\n  Packages are maintained by us. That is, we compile them from source ourselves (into .rpm, .deb, or .apk packages), or we write the software packages ourselves (e.g., composer, pip, npm, dep).\n  Your criteria may look different, and that\u0026rsquo;s OK. Some engineering teams are better at this, while others are still maturing.\nIf you don\u0026rsquo;t have criteria, and generally just install software from anywhere, I have two pieces of advice.\n  Stop it.\n  Our criteria has been very good to us. Feel free to borrow ours.\n  ",
        "source":"\n{{\u003cdescription\u003e}}\nOnly a tiny fraction of the code your application runs was written by you or your team. How do you know you can trust the code that was written by other people? Where would you even start?\n{{\u003c/description\u003e}}\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/trust-dial@2x.jpg\" alt=\"Trust dial\"\u003e}}\n\n{{% aside %}}\nThis piece is part of a larger series on [Engineering for Site Reliability](/series/engineering-for-site-reliability/), specifically _balancing stability against the edge of technology_.\n{{% /aside %}}\n\n## What do I mean by \"trust\"?\n\nMovies and TV shows have given us a version of trust which essentially boils down to “Do you trust me?” as they hold out their hand to another person. In the movies things generally work out in the end, even if they run into a little more trouble along the way. This is the kind of trust that teenagers, newly in-love, have with their new person.\n\nThis is also the kind of trust that most engineers have in their software dependencies. **This is not what trust is**, and is a **high-risk** way to build applications.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/teen-titans@2x.jpg\" alt=\"Teen Titans\" \u003e}}\n\nIf you've ever been spurned by an ex-lover, or have grown-up around shady people, you'll likely have a different definition of trust. A marriage counselor may say something like \"trust, but verify\". A person who has grown-up in a bad neighborhood or around shady people may have the perspective that _trust is earned, not given_. **A certain amount of paranoia is a good thing**.\n\nHowever, as with everything, you can also have too much paranoia. These are the teams who ship an application, and if it's not broken, they don't touch it. Their curse is that they fall so far behind the security and maintenance curves, that their applications become ticking time bombs — defeating the very purpose they think their paranoia addresses.\n\nThe point that I'd like you to take away from this is that _trust is earned, not given_. When you come from this perspective, you make better technical decisions.\n\n## What is my application?\n\nDepending on the type of engineer you are (front-end, backend, ops), you may look at the applications you work on through different lenses.\n\n* Some see the client-side, browser code they're writing.\n* Some see the Golang, Node.js, Python, or PHP code they're writing. \n* Some see the package dependencies, and their package dependencies, and so on…\n* Some see code like the Docker runtime, OpenSSL, cURL, or the Linux kernel.\n\nIn truth, _all of these answers are correct_. The best engineers know how important it is to look at the entire stack — from the application, to the runtime, to the hypervisor, to the kernel.\n\n## Reusable layers, and understanding trust\n\nIt's a common (and extremely sensible) pattern to re-use and build atop existing technology layers. By leveraging this powerful foundation, we can build bigger, better, and more powerful appications and services! But we also need to understand how core concepts like _trust_ work between all of these layers.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/wrong-way@2x.jpg\" alt=\"Wrong way sign\"\u003e}}\n\nLet me give a few examples of anti-patterns that are also very commonplace in many organizations (mostly due to ignorance, as opposed to malice):\n\n\u003e **NOTE:** I'm speaking from a context of applications which run on popular cloud infrastructure services like AWS, GCP, or Azure, and have sane processes in place like actively-supported system images (e.g., AMIs).\n\n* Fetching application dependencies _live_ from upstream sources (e.g., the internet is ephemeral; is your app?).\n\n* Running package manager updates when spinning-up a new machine (e.g., modifying the underlying system image at boot-time; `yum -y update`).\n\n* Running package manager updates when deploying to Production (e.g., picking up potentially untested software without a testing stage in-between).\n\n* Adding new package manager repositories from random places on the internet (e.g., taking candy from strangers).\n\n* Relying exclusively on a single _availability zone_ or _region_ from their cloud infrastructure provider.\n\n“These aren’t anti-patterns,” you say. “They’re just how development is done.”\n\nThank you for your thoughts, hypothetical reader. But consider the following:\n\n### An unpublished package broke the internet\n\nIn case you forgot, in early 2016, _one package_ [broke the entire Node.js ecosystem]({{% wayback \"https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm\" %}}).\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/broken-collarbone@2x.jpg\" alt=\"Broken collarbone\"\u003e}}\n\nDavid Haney writes in his piece “[NPM \u0026 left-pad: Have We Forgotten How To Program?]({{% wayback \"https://www.davidhaney.io/npm-left-pad-have-we-forgotten-how-to-program/\" %}})”:\n\n\u003e Okay developers, time to have a serious talk. As you are probably already aware, this week React, Babel, and a bunch of other high-profile packages on NPM broke. The reason they broke is rather astounding:\n\u003e\n\u003e A simple NPM package called _left-pad_ that was a dependency of their code.\n\u003e\n\u003e _left-pad_, at the time of writing this, has 11 stars on GitHub. The entire package is 11 simple lines that implement a basic left-pad string function. […]\n\u003e\n\u003e What concerns me here is that _so many packages and projects_ took on a **dependency** for a simple left padding string function, rather than their developers taking 2 minutes to write such a basic function themselves.\n\nEach and every application team which was hit by this issue, and allowed it to impact a Production-facing deployment, **failed to understand trust**.\n\nIn this case, they should have implemented a _package caching system_, which can fetch a dependency on the first request, then cache that version for all subsequent requests. That way, if there is an issue with an upstream source, you will not be impacted.\n\n### Crashing the entire stack\n\nI was working at Amazon Web Services back in 2010 when [AWS Elastic Beanstalk]({{% wayback \"https://aws.amazon.com/elasticbeanstalk/\" %}}) was still in development. The team was working to build an easy-to-use solution around the idea of \"application containers\" (back before Docker was spun-out from [dotCloud]({{% wayback \"https://www.crunchbase.com/organization/dotcloud\" %}}), an early PaaS provider). At the time I was helping them add PHP + Apache support to Elastic Beanstalk in time for launch, as I was the _de-facto_ “PHP guy” in AWS.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/etc-passwd@2x.jpg\" alt=\"/etc/passwd\"\u003e}}\n\nDevelopment was running on a pre-release version of what would become [Amazon Linux]({{% wayback \"https://aws.amazon.com/amazon-linux-ami/\" %}}). The original configuration was designed to run `yum -y update` on boot, which essentially means _pick up the latest versions of all installed packages_. While the team was thinking about system security (and avoiding outdated packages), everything broke on the day that the Amazon Linux team published a new version of Apache with backwards-incompatible changes. The development team **failed to understand trust**.\n\nFortunately, it was a little before the public launch, and so only a few internal beta customers and developers were impacted. But watching that incident was the day that I learned that you don't _arbitrarily_ install all system updates. You should do that in your development environment instead, work out the issues, then roll something out to Production that has been tested and works as expected.\n\n### Dev/Prod parity\n\nIf you've never heard of the [12-factor app methodology]({{% wayback \"https://www.12factor.net\" %}}), you are absolutely missing out. One of the chapters is entitled “[Dev/prod parity]({{% wayback \"https://www.12factor.net/dev-prod-parity\" %}})”, which essentially boils down to _keeping development, staging, and production as similar as possible_.\n\nOne thing that I've seen bite a team is that they were deploying an application by pushing the source code from Git to the production instances, then resolving their packages _directly on the instance_. (To be fair, this was back in the days when [Capistrano]({{% wayback \"https://capistranorb.com\" %}}) was hot, and we've come a long way since then.)\n\nBut even in the world of Docker and _continuous integration_, I still see similar things happen. A team will build a Docker image for their dev app in their CI pipeline, push it to their Docker repository, then deploy it to dev. Then they build the image again when deploying to staging. Then again when they deploy to Prod. **This is the same problem!** The dependencies are not being tested appropriately in the earlier environments before progressing to the production environment.\n\nWith Docker, some teams have figured out how to make the exact same mistakes even faster! Those teams have **failed to understand trust**.\n\nInstead, you should build the production-ready Docker image _once_, then promote that same image up to each environment as the requisite confidence is built.\n\n“But how do I include my development dependencies inside my Docker container?”\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/batman-slap-docker-dev@2x.jpg\" alt=\"Batman slaps Robin\"\u003e}}\n\nDocker images that are built should be the exact same bytes, regardless of the environment. Your dev build should write out logs in the same way as your Production app would (although perhaps to a local location). You should be able to define things like environment variables that are read by the Docker daemon at container launch. Or by defining a local volume to mount containing configuration information. But the insides of the Docker image should always be completely identical between environments.\n\n## Guidelines for trust\n\nWhen you're provisioning software onto a machine that will run in Production, you don't want to be running software from _anywhere_. You need to know that you can _trust_ the source of the software before you ship it into Production.\n\nIn my case, I tend to work on teams which run servers with a blend of RedHat Enterprise Linux (RHEL), CentOS, and Amazon Linux. Containers are commonly Ubuntu, Debian, or Alpine. I work with applications written in nearly every major programming language. These are my criteria for determining whether or not to trust a package or Docker image.\n\n1. Packages are maintained by CentOS, RedHat, Amazon, Ubuntu, Debian, Alpine, etc., directly.\n\n1. Packages are maintained by the vendor of the software directly (e.g., Docker, Amazon, PHP, Node Foundation, Angular, Kubernetes).\n\n1. Packages are maintained by a reputable third-party source (as few of these as possible; e.g., [NodeSource](https://github.com/nodesource/distributions)).\n\n1. Packages are maintained by us. That is, we compile them from source ourselves (into `.rpm`, `.deb`, or `.apk` packages), or we write the software packages ourselves (e.g., `composer`, `pip`, `npm`, `dep`).\n\nYour criteria may look different, and that's OK. Some engineering teams are better at this, while others are still maturing.\n\nIf you don't have criteria, and generally just install software from anywhere, I have two pieces of advice.\n\n1. Stop it.\n\n1. Our criteria has been very good to us. Feel free to borrow ours.\n"},
    "links": {
        "prev": {"title": "The Hiring Process, Part I", "permalink": "https://ryanparman.com/posts/2018/the-hiring-process-part-i-what-i-look-for-in-a-cv-resume-remastered/"},
        "next": {"title": "Playlist: Best of P.O.D.", "permalink": "https://ryanparman.com/posts/2019/playlist-best-of-pod/"},
        "ignore": "me"
    }
}

            
        ]
    }
}
