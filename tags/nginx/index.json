{
    "data": {
        
        
        "taxonomy": "tag",
        "term": "nginx",
        
        "count": 2,
        "items": [
            
            {
    "kind": "page",
    "title": "Understanding Trust in Your Infrastructure",
    "description": "Trust should be earned, not given blindly.",
    "summary": {
        "content": "Only a tiny fraction of the code your application runs was written by you or your team. How do you know you can trust the code that was written by other people? Where would you even start? This piece is part of a larger series on Engineering for Site Reliability, specifically balancing stability against the edge of technology. What do I mean by \u0026ldquo;trust\u0026rdquo;? Movies and TV shows have given us a version of trust which essentially boils down to “Do you trust me?",
        "isTruncated": true
    },
    "published": "2018-12-27T07:30:30Z",
    "updated": "2019-02-10T21:35:12-08:00",
    "permalink": "https://ryanparman.com/posts/2018/understanding-trust-in-your-infrastructure/",
    "relativePermalink": "/posts/2018/understanding-trust-in-your-infrastructure/",
    "aliases": ["/2018/12/27/understanding-trust-in-your-infrastructure"],
    "images": ["https://cdn.ryanparman.com/hugo/posts/2018/trust-dial@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/broken-collarbone@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/teen-titans@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/wrong-way@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/etc-passwd@2x.jpg", "https://cdn.ryanparman.com/hugo/posts/2018/batman-slap-docker-dev@2x.jpg", "https://cdn.ryanparman.com/hugo/headers/understanding-trust/severed-wrists@2x.jpg"],
    "videos": [],
    "categories": ["Engineering for Site Reliability"],
    "tags": ["trust", "docker", "alpine linux", "centos", "ubuntu", "rhel", "php", "python", "nodejs", "golang", "nginx", "composer", "pip", "npm", "java", "cve", "security", "site reliability engineering"],
    "series": ["Engineering for Site Reliability"],
    "keywords": [],
    "meta": {
        "wordCount": 1608,
        "readingTime": "8 minutes",
        "language": "en",
        "isDraft": false,
        "isHome": false,
        "isNode": false,
        "isPage": true,
        "isTranslated": false
    },
    "sourceFile": {
        "path": "posts/2018/20181227-understanding-trust-in-your-infrastructure.md",
        "logicalName": "20181227-understanding-trust-in-your-infrastructure.md",
        "translationBaseName": "20181227-understanding-trust-in-your-infrastructure",
        "baseFileName": "20181227-understanding-trust-in-your-infrastructure",
        "ext": "md",
        "lang": "en",
        "dir": "posts/2018/"
    },
    "content": {
        "tableOfContents": "\u003cnav id=\"TableOfContents\"\u003e\n  \u003cul\u003e\n    \u003cli\u003e\u003ca href=\"#what-do-i-mean-by-trust\"\u003eWhat do I mean by \u0026ldquo;trust\u0026rdquo;?\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#what-is-my-application\"\u003eWhat is my application?\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#reusable-layers-and-understanding-trust\"\u003eReusable layers, and understanding trust\u003c/a\u003e\n      \u003cul\u003e\n        \u003cli\u003e\u003ca href=\"#an-unpublished-package-broke-the-internet\"\u003eAn unpublished package broke the internet\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#crashing-the-entire-stack\"\u003eCrashing the entire stack\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#devprod-parity\"\u003eDev/Prod parity\u003c/a\u003e\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#guidelines-for-trust\"\u003eGuidelines for trust\u003c/a\u003e\u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/nav\u003e",
        "html":"\u003cp itemprop=\"description\" class=\"f5 f4-m f3-l mt0 lh-copy p-summary entry-summary\"\u003e\nOnly a tiny fraction of the code your application runs was written by you or your team. How do you know you can trust the code that was written by other people? Where would you even start?\n\u003c/p\u003e\n\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/trust-dial@2x.jpg\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\n\u003caside class=\"age aside container flex\"\u003e\u003cp\u003eThis piece is part of a larger series on \u003ca href=\"/series/engineering-for-site-reliability/\"\u003eEngineering for Site Reliability\u003c/a\u003e, specifically \u003cem\u003ebalancing stability against the edge of technology\u003c/em\u003e.\u003c/p\u003e\n\u003c/aside\u003e\n\n\u003ch2 id=\"what-do-i-mean-by-trust\"\u003eWhat do I mean by \u0026ldquo;trust\u0026rdquo;?\u003c/h2\u003e\n\u003cp\u003eMovies and TV shows have given us a version of trust which essentially boils down to “Do you trust me?” as they hold out their hand to another person. In the movies things generally work out in the end, even if they run into a little more trouble along the way. This is the kind of trust that teenagers, newly in-love, have with their new person.\u003c/p\u003e\n\u003cp\u003eThis is also the kind of trust that most engineers have in their software dependencies. \u003cstrong\u003eThis is not what trust is\u003c/strong\u003e, and is a \u003cstrong\u003ehigh-risk\u003c/strong\u003e way to build applications.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/teen-titans@2x.jpg\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eIf you\u0026rsquo;ve ever been spurned by an ex-lover, or have grown-up around shady people, you\u0026rsquo;ll likely have a different definition of trust. A marriage counselor may say something like \u0026ldquo;trust, but verify\u0026rdquo;. A person who has grown-up in a bad neighborhood or around shady people may have the perspective that \u003cem\u003etrust is earned, not given\u003c/em\u003e. \u003cstrong\u003eA certain amount of paranoia is a good thing\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eHowever, as with everything, you can also have too much paranoia. These are the teams who ship an application, and if it\u0026rsquo;s not broken, they don\u0026rsquo;t touch it. Their curse is that they fall so far behind the security and maintenance curves, that their applications become ticking time bombs — defeating the very purpose they think their paranoia addresses.\u003c/p\u003e\n\u003cp\u003eThe point that I\u0026rsquo;d like you to take away from this is that \u003cem\u003etrust is earned, not given\u003c/em\u003e. When you come from this perspective, you make better technical decisions.\u003c/p\u003e\n\u003ch2 id=\"what-is-my-application\"\u003eWhat is my application?\u003c/h2\u003e\n\u003cp\u003eDepending on the type of engineer you are (front-end, backend, ops), you may look at the applications you work on through different lenses.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSome see the client-side, browser code they\u0026rsquo;re writing.\u003c/li\u003e\n\u003cli\u003eSome see the Golang, Node.js, Python, or PHP code they\u0026rsquo;re writing.\u003c/li\u003e\n\u003cli\u003eSome see the package dependencies, and their package dependencies, and so on…\u003c/li\u003e\n\u003cli\u003eSome see code like the Docker runtime, OpenSSL, cURL, or the Linux kernel.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn truth, \u003cem\u003eall of these answers are correct\u003c/em\u003e. The best engineers know how important it is to look at the entire stack — from the application, to the runtime, to the hypervisor, to the kernel.\u003c/p\u003e\n\u003ch2 id=\"reusable-layers-and-understanding-trust\"\u003eReusable layers, and understanding trust\u003c/h2\u003e\n\u003cp\u003eIt\u0026rsquo;s a common (and extremely sensible) pattern to re-use and build atop existing technology layers. By leveraging this powerful foundation, we can build bigger, better, and more powerful appications and services! But we also need to understand how core concepts like \u003cem\u003etrust\u003c/em\u003e work between all of these layers.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/wrong-way@2x.jpg\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eLet me give a few examples of anti-patterns that are also very commonplace in many organizations (mostly due to ignorance, as opposed to malice):\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eNOTE:\u003c/strong\u003e I\u0026rsquo;m speaking from a context of applications which run on popular cloud infrastructure services like AWS, GCP, or Azure, and have sane processes in place like actively-supported system images (e.g., AMIs).\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eFetching application dependencies \u003cem\u003elive\u003c/em\u003e from upstream sources (e.g., the internet is ephemeral; is your app?).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRunning package manager updates when spinning-up a new machine (e.g., modifying the underlying system image at boot-time; \u003ccode\u003eyum -y update\u003c/code\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRunning package manager updates when deploying to Production (e.g., picking up potentially untested software without a testing stage in-between).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAdding new package manager repositories from random places on the internet (e.g., taking candy from strangers).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRelying exclusively on a single \u003cem\u003eavailability zone\u003c/em\u003e or \u003cem\u003eregion\u003c/em\u003e from their cloud infrastructure provider.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e“These aren’t anti-patterns,” you say. “They’re just how development is done.”\u003c/p\u003e\n\u003cp\u003eThank you for your thoughts, hypothetical reader. But consider the following:\u003c/p\u003e\n\u003ch3 id=\"an-unpublished-package-broke-the-internet\"\u003eAn unpublished package broke the internet\u003c/h3\u003e\n\u003cp\u003eIn case you forgot, in early 2016, \u003cem\u003eone package\u003c/em\u003e \u003ca href=\"https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm\"\u003ebroke the entire Node.js ecosystem\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/broken-collarbone@2x.jpg\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eDavid Haney writes in his piece “\u003ca href=\"https://www.davidhaney.io/npm-left-pad-have-we-forgotten-how-to-program/\"\u003eNPM \u0026amp; left-pad: Have We Forgotten How To Program?\u003c/a\u003e”:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eOkay developers, time to have a serious talk. As you are probably already aware, this week React, Babel, and a bunch of other high-profile packages on NPM broke. The reason they broke is rather astounding:\u003c/p\u003e\n\u003cp\u003eA simple NPM package called \u003cem\u003eleft-pad\u003c/em\u003e that was a dependency of their code.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eleft-pad\u003c/em\u003e, at the time of writing this, has 11 stars on GitHub. The entire package is 11 simple lines that implement a basic left-pad string function. […]\u003c/p\u003e\n\u003cp\u003eWhat concerns me here is that \u003cem\u003eso many packages and projects\u003c/em\u003e took on a \u003cstrong\u003edependency\u003c/strong\u003e for a simple left padding string function, rather than their developers taking 2 minutes to write such a basic function themselves.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eEach and every application team which was hit by this issue, and allowed it to impact a Production-facing deployment, \u003cstrong\u003efailed to understand trust\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eIn this case, they should have implemented a \u003cem\u003epackage caching system\u003c/em\u003e, which can fetch a dependency on the first request, then cache that version for all subsequent requests. That way, if there is an issue with an upstream source, you will not be impacted.\u003c/p\u003e\n\u003ch3 id=\"crashing-the-entire-stack\"\u003eCrashing the entire stack\u003c/h3\u003e\n\u003cp\u003eI was working at Amazon Web Services back in 2010 when \u003ca href=\"https://aws.amazon.com/elasticbeanstalk/\"\u003eAWS Elastic Beanstalk\u003c/a\u003e was still in development. The team was working to build an easy-to-use solution around the idea of \u0026ldquo;application containers\u0026rdquo; (back before Docker was spun-out from \u003ca href=\"https://www.crunchbase.com/organization/dotcloud\"\u003edotCloud\u003c/a\u003e, an early PaaS provider). At the time I was helping them add PHP + Apache support to Elastic Beanstalk in time for launch, as I was the \u003cem\u003ede-facto\u003c/em\u003e “PHP guy” in AWS.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/etc-passwd@2x.jpg\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eDevelopment was running on a pre-release version of what would become \u003ca href=\"https://aws.amazon.com/amazon-linux-ami/\"\u003eAmazon Linux\u003c/a\u003e. The original configuration was designed to run \u003ccode\u003eyum -y update\u003c/code\u003e on boot, which essentially means \u003cem\u003epick up the latest versions of all installed packages\u003c/em\u003e. While the team was thinking about system security (and avoiding outdated packages), everything broke on the day that the Amazon Linux team published a new version of Apache with backwards-incompatible changes. The development team \u003cstrong\u003efailed to understand trust\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eFortunately, it was a little before the public launch, and so only a few internal beta customers and developers were impacted. But watching that incident was the day that I learned that you don\u0026rsquo;t \u003cem\u003earbitrarily\u003c/em\u003e install all system updates. You should do that in your development environment instead, work out the issues, then roll something out to Production that has been tested and works as expected.\u003c/p\u003e\n\u003ch3 id=\"devprod-parity\"\u003eDev/Prod parity\u003c/h3\u003e\n\u003cp\u003eIf you\u0026rsquo;ve never heard of the \u003ca href=\"https://www.12factor.net\"\u003e12-factor app methodology\u003c/a\u003e, you are absolutely missing out. One of the chapters is entitled “\u003ca href=\"https://www.12factor.net/dev-prod-parity\"\u003eDev/prod parity\u003c/a\u003e”, which essentially boils down to \u003cem\u003ekeeping development, staging, and production as similar as possible\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eOne thing that I\u0026rsquo;ve seen bite a team is that they were deploying an application by pushing the source code from Git to the production instances, then resolving their packages \u003cem\u003edirectly on the instance\u003c/em\u003e. (To be fair, this was back in the days when \u003ca href=\"https://capistranorb.com\"\u003eCapistrano\u003c/a\u003e was hot, and we\u0026rsquo;ve come a long way since then.)\u003c/p\u003e\n\u003cp\u003eBut even in the world of Docker and \u003cem\u003econtinuous integration\u003c/em\u003e, I still see similar things happen. A team will build a Docker image for their dev app in their CI pipeline, push it to their Docker repository, then deploy it to dev. Then they build the image again when deploying to staging. Then again when they deploy to Prod. \u003cstrong\u003eThis is the same problem!\u003c/strong\u003e The dependencies are not being tested appropriately in the earlier environments before progressing to the production environment.\u003c/p\u003e\n\u003cp\u003eWith Docker, some teams have figured out how to make the exact same mistakes even faster! Those teams have \u003cstrong\u003efailed to understand trust\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eInstead, you should build the production-ready Docker image \u003cem\u003eonce\u003c/em\u003e, then promote that same image up to each environment as the requisite confidence is built.\u003c/p\u003e\n\u003cp\u003e“But how do I include my development dependencies inside my Docker container?”\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/batman-slap-docker-dev@2x.jpg\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eDocker images that are built should be the exact same bytes, regardless of the environment. Your dev build should write out logs in the same way as your Production app would (although perhaps to a local location). You should be able to define things like environment variables that are read by the Docker daemon at container launch. Or by defining a local volume to mount containing configuration information. But the insides of the Docker image should always be completely identical between environments.\u003c/p\u003e\n\u003ch2 id=\"guidelines-for-trust\"\u003eGuidelines for trust\u003c/h2\u003e\n\u003cp\u003eWhen you\u0026rsquo;re provisioning software onto a machine that will run in Production, you don\u0026rsquo;t want to be running software from \u003cem\u003eanywhere\u003c/em\u003e. You need to know that you can \u003cem\u003etrust\u003c/em\u003e the source of the software before you ship it into Production.\u003c/p\u003e\n\u003cp\u003eIn my case, I tend to work on teams which run servers with a blend of RedHat Enterprise Linux (RHEL), CentOS, and Amazon Linux. Containers are commonly Ubuntu, Debian, or Alpine. I work with applications written in nearly every major programming language. These are my criteria for determining whether or not to trust a package or Docker image.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ePackages are maintained by CentOS, RedHat, Amazon, Ubuntu, Debian, Alpine, etc., directly.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePackages are maintained by the vendor of the software directly (e.g., Docker, Amazon, PHP, Node Foundation, Angular, Kubernetes).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePackages are maintained by a reputable third-party source (as few of these as possible; e.g., \u003ca href=\"https://github.com/nodesource/distributions\"\u003eNodeSource\u003c/a\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePackages are maintained by us. That is, we compile them from source ourselves (into \u003ccode\u003e.rpm\u003c/code\u003e, \u003ccode\u003e.deb\u003c/code\u003e, or \u003ccode\u003e.apk\u003c/code\u003e packages), or we write the software packages ourselves (e.g., \u003ccode\u003ecomposer\u003c/code\u003e, \u003ccode\u003epip\u003c/code\u003e, \u003ccode\u003enpm\u003c/code\u003e, \u003ccode\u003edep\u003c/code\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eYour criteria may look different, and that\u0026rsquo;s OK. Some engineering teams are better at this, while others are still maturing.\u003c/p\u003e\n\u003cp\u003eIf you don\u0026rsquo;t have criteria, and generally just install software from anywhere, I have two pieces of advice.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eStop it.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOur criteria has been very good to us. Feel free to borrow ours.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n",
        "plain":"Only a tiny fraction of the code your application runs was written by you or your team. How do you know you can trust the code that was written by other people? Where would you even start?   This piece is part of a larger series on Engineering for Site Reliability, specifically balancing stability against the edge of technology.\n What do I mean by \u0026ldquo;trust\u0026rdquo;? Movies and TV shows have given us a version of trust which essentially boils down to “Do you trust me?” as they hold out their hand to another person. In the movies things generally work out in the end, even if they run into a little more trouble along the way. This is the kind of trust that teenagers, newly in-love, have with their new person.\nThis is also the kind of trust that most engineers have in their software dependencies. This is not what trust is, and is a high-risk way to build applications.\n  If you\u0026rsquo;ve ever been spurned by an ex-lover, or have grown-up around shady people, you\u0026rsquo;ll likely have a different definition of trust. A marriage counselor may say something like \u0026ldquo;trust, but verify\u0026rdquo;. A person who has grown-up in a bad neighborhood or around shady people may have the perspective that trust is earned, not given. A certain amount of paranoia is a good thing.\nHowever, as with everything, you can also have too much paranoia. These are the teams who ship an application, and if it\u0026rsquo;s not broken, they don\u0026rsquo;t touch it. Their curse is that they fall so far behind the security and maintenance curves, that their applications become ticking time bombs — defeating the very purpose they think their paranoia addresses.\nThe point that I\u0026rsquo;d like you to take away from this is that trust is earned, not given. When you come from this perspective, you make better technical decisions.\nWhat is my application? Depending on the type of engineer you are (front-end, backend, ops), you may look at the applications you work on through different lenses.\n Some see the client-side, browser code they\u0026rsquo;re writing. Some see the Golang, Node.js, Python, or PHP code they\u0026rsquo;re writing. Some see the package dependencies, and their package dependencies, and so on… Some see code like the Docker runtime, OpenSSL, cURL, or the Linux kernel.  In truth, all of these answers are correct. The best engineers know how important it is to look at the entire stack — from the application, to the runtime, to the hypervisor, to the kernel.\nReusable layers, and understanding trust It\u0026rsquo;s a common (and extremely sensible) pattern to re-use and build atop existing technology layers. By leveraging this powerful foundation, we can build bigger, better, and more powerful appications and services! But we also need to understand how core concepts like trust work between all of these layers.\n  Let me give a few examples of anti-patterns that are also very commonplace in many organizations (mostly due to ignorance, as opposed to malice):\n NOTE: I\u0026rsquo;m speaking from a context of applications which run on popular cloud infrastructure services like AWS, GCP, or Azure, and have sane processes in place like actively-supported system images (e.g., AMIs).\n   Fetching application dependencies live from upstream sources (e.g., the internet is ephemeral; is your app?).\n  Running package manager updates when spinning-up a new machine (e.g., modifying the underlying system image at boot-time; yum -y update).\n  Running package manager updates when deploying to Production (e.g., picking up potentially untested software without a testing stage in-between).\n  Adding new package manager repositories from random places on the internet (e.g., taking candy from strangers).\n  Relying exclusively on a single availability zone or region from their cloud infrastructure provider.\n  “These aren’t anti-patterns,” you say. “They’re just how development is done.”\nThank you for your thoughts, hypothetical reader. But consider the following:\nAn unpublished package broke the internet In case you forgot, in early 2016, one package broke the entire Node.js ecosystem.\n  David Haney writes in his piece “NPM \u0026amp; left-pad: Have We Forgotten How To Program?”:\n Okay developers, time to have a serious talk. As you are probably already aware, this week React, Babel, and a bunch of other high-profile packages on NPM broke. The reason they broke is rather astounding:\nA simple NPM package called left-pad that was a dependency of their code.\nleft-pad, at the time of writing this, has 11 stars on GitHub. The entire package is 11 simple lines that implement a basic left-pad string function. […]\nWhat concerns me here is that so many packages and projects took on a dependency for a simple left padding string function, rather than their developers taking 2 minutes to write such a basic function themselves.\n Each and every application team which was hit by this issue, and allowed it to impact a Production-facing deployment, failed to understand trust.\nIn this case, they should have implemented a package caching system, which can fetch a dependency on the first request, then cache that version for all subsequent requests. That way, if there is an issue with an upstream source, you will not be impacted.\nCrashing the entire stack I was working at Amazon Web Services back in 2010 when AWS Elastic Beanstalk was still in development. The team was working to build an easy-to-use solution around the idea of \u0026ldquo;application containers\u0026rdquo; (back before Docker was spun-out from dotCloud, an early PaaS provider). At the time I was helping them add PHP + Apache support to Elastic Beanstalk in time for launch, as I was the de-facto “PHP guy” in AWS.\n  Development was running on a pre-release version of what would become Amazon Linux. The original configuration was designed to run yum -y update on boot, which essentially means pick up the latest versions of all installed packages. While the team was thinking about system security (and avoiding outdated packages), everything broke on the day that the Amazon Linux team published a new version of Apache with backwards-incompatible changes. The development team failed to understand trust.\nFortunately, it was a little before the public launch, and so only a few internal beta customers and developers were impacted. But watching that incident was the day that I learned that you don\u0026rsquo;t arbitrarily install all system updates. You should do that in your development environment instead, work out the issues, then roll something out to Production that has been tested and works as expected.\nDev/Prod parity If you\u0026rsquo;ve never heard of the 12-factor app methodology, you are absolutely missing out. One of the chapters is entitled “Dev/prod parity”, which essentially boils down to keeping development, staging, and production as similar as possible.\nOne thing that I\u0026rsquo;ve seen bite a team is that they were deploying an application by pushing the source code from Git to the production instances, then resolving their packages directly on the instance. (To be fair, this was back in the days when Capistrano was hot, and we\u0026rsquo;ve come a long way since then.)\nBut even in the world of Docker and continuous integration, I still see similar things happen. A team will build a Docker image for their dev app in their CI pipeline, push it to their Docker repository, then deploy it to dev. Then they build the image again when deploying to staging. Then again when they deploy to Prod. This is the same problem! The dependencies are not being tested appropriately in the earlier environments before progressing to the production environment.\nWith Docker, some teams have figured out how to make the exact same mistakes even faster! Those teams have failed to understand trust.\nInstead, you should build the production-ready Docker image once, then promote that same image up to each environment as the requisite confidence is built.\n“But how do I include my development dependencies inside my Docker container?”\n  Docker images that are built should be the exact same bytes, regardless of the environment. Your dev build should write out logs in the same way as your Production app would (although perhaps to a local location). You should be able to define things like environment variables that are read by the Docker daemon at container launch. Or by defining a local volume to mount containing configuration information. But the insides of the Docker image should always be completely identical between environments.\nGuidelines for trust When you\u0026rsquo;re provisioning software onto a machine that will run in Production, you don\u0026rsquo;t want to be running software from anywhere. You need to know that you can trust the source of the software before you ship it into Production.\nIn my case, I tend to work on teams which run servers with a blend of RedHat Enterprise Linux (RHEL), CentOS, and Amazon Linux. Containers are commonly Ubuntu, Debian, or Alpine. I work with applications written in nearly every major programming language. These are my criteria for determining whether or not to trust a package or Docker image.\n  Packages are maintained by CentOS, RedHat, Amazon, Ubuntu, Debian, Alpine, etc., directly.\n  Packages are maintained by the vendor of the software directly (e.g., Docker, Amazon, PHP, Node Foundation, Angular, Kubernetes).\n  Packages are maintained by a reputable third-party source (as few of these as possible; e.g., NodeSource).\n  Packages are maintained by us. That is, we compile them from source ourselves (into .rpm, .deb, or .apk packages), or we write the software packages ourselves (e.g., composer, pip, npm, dep).\n  Your criteria may look different, and that\u0026rsquo;s OK. Some engineering teams are better at this, while others are still maturing.\nIf you don\u0026rsquo;t have criteria, and generally just install software from anywhere, I have two pieces of advice.\n  Stop it.\n  Our criteria has been very good to us. Feel free to borrow ours.\n  ",
        "source":"\n{{\u003cdescription\u003e}}\nOnly a tiny fraction of the code your application runs was written by you or your team. How do you know you can trust the code that was written by other people? Where would you even start?\n{{\u003c/description\u003e}}\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/trust-dial@2x.jpg\" alt=\"Trust dial\"\u003e}}\n\n{{% aside %}}\nThis piece is part of a larger series on [Engineering for Site Reliability](/series/engineering-for-site-reliability/), specifically _balancing stability against the edge of technology_.\n{{% /aside %}}\n\n## What do I mean by \"trust\"?\n\nMovies and TV shows have given us a version of trust which essentially boils down to “Do you trust me?” as they hold out their hand to another person. In the movies things generally work out in the end, even if they run into a little more trouble along the way. This is the kind of trust that teenagers, newly in-love, have with their new person.\n\nThis is also the kind of trust that most engineers have in their software dependencies. **This is not what trust is**, and is a **high-risk** way to build applications.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/teen-titans@2x.jpg\" alt=\"Teen Titans\" \u003e}}\n\nIf you've ever been spurned by an ex-lover, or have grown-up around shady people, you'll likely have a different definition of trust. A marriage counselor may say something like \"trust, but verify\". A person who has grown-up in a bad neighborhood or around shady people may have the perspective that _trust is earned, not given_. **A certain amount of paranoia is a good thing**.\n\nHowever, as with everything, you can also have too much paranoia. These are the teams who ship an application, and if it's not broken, they don't touch it. Their curse is that they fall so far behind the security and maintenance curves, that their applications become ticking time bombs — defeating the very purpose they think their paranoia addresses.\n\nThe point that I'd like you to take away from this is that _trust is earned, not given_. When you come from this perspective, you make better technical decisions.\n\n## What is my application?\n\nDepending on the type of engineer you are (front-end, backend, ops), you may look at the applications you work on through different lenses.\n\n* Some see the client-side, browser code they're writing.\n* Some see the Golang, Node.js, Python, or PHP code they're writing. \n* Some see the package dependencies, and their package dependencies, and so on…\n* Some see code like the Docker runtime, OpenSSL, cURL, or the Linux kernel.\n\nIn truth, _all of these answers are correct_. The best engineers know how important it is to look at the entire stack — from the application, to the runtime, to the hypervisor, to the kernel.\n\n## Reusable layers, and understanding trust\n\nIt's a common (and extremely sensible) pattern to re-use and build atop existing technology layers. By leveraging this powerful foundation, we can build bigger, better, and more powerful appications and services! But we also need to understand how core concepts like _trust_ work between all of these layers.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/wrong-way@2x.jpg\" alt=\"Wrong way sign\"\u003e}}\n\nLet me give a few examples of anti-patterns that are also very commonplace in many organizations (mostly due to ignorance, as opposed to malice):\n\n\u003e **NOTE:** I'm speaking from a context of applications which run on popular cloud infrastructure services like AWS, GCP, or Azure, and have sane processes in place like actively-supported system images (e.g., AMIs).\n\n* Fetching application dependencies _live_ from upstream sources (e.g., the internet is ephemeral; is your app?).\n\n* Running package manager updates when spinning-up a new machine (e.g., modifying the underlying system image at boot-time; `yum -y update`).\n\n* Running package manager updates when deploying to Production (e.g., picking up potentially untested software without a testing stage in-between).\n\n* Adding new package manager repositories from random places on the internet (e.g., taking candy from strangers).\n\n* Relying exclusively on a single _availability zone_ or _region_ from their cloud infrastructure provider.\n\n“These aren’t anti-patterns,” you say. “They’re just how development is done.”\n\nThank you for your thoughts, hypothetical reader. But consider the following:\n\n### An unpublished package broke the internet\n\nIn case you forgot, in early 2016, _one package_ [broke the entire Node.js ecosystem]({{% wayback \"https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm\" %}}).\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/broken-collarbone@2x.jpg\" alt=\"Broken collarbone\"\u003e}}\n\nDavid Haney writes in his piece “[NPM \u0026 left-pad: Have We Forgotten How To Program?]({{% wayback \"https://www.davidhaney.io/npm-left-pad-have-we-forgotten-how-to-program/\" %}})”:\n\n\u003e Okay developers, time to have a serious talk. As you are probably already aware, this week React, Babel, and a bunch of other high-profile packages on NPM broke. The reason they broke is rather astounding:\n\u003e\n\u003e A simple NPM package called _left-pad_ that was a dependency of their code.\n\u003e\n\u003e _left-pad_, at the time of writing this, has 11 stars on GitHub. The entire package is 11 simple lines that implement a basic left-pad string function. […]\n\u003e\n\u003e What concerns me here is that _so many packages and projects_ took on a **dependency** for a simple left padding string function, rather than their developers taking 2 minutes to write such a basic function themselves.\n\nEach and every application team which was hit by this issue, and allowed it to impact a Production-facing deployment, **failed to understand trust**.\n\nIn this case, they should have implemented a _package caching system_, which can fetch a dependency on the first request, then cache that version for all subsequent requests. That way, if there is an issue with an upstream source, you will not be impacted.\n\n### Crashing the entire stack\n\nI was working at Amazon Web Services back in 2010 when [AWS Elastic Beanstalk]({{% wayback \"https://aws.amazon.com/elasticbeanstalk/\" %}}) was still in development. The team was working to build an easy-to-use solution around the idea of \"application containers\" (back before Docker was spun-out from [dotCloud]({{% wayback \"https://www.crunchbase.com/organization/dotcloud\" %}}), an early PaaS provider). At the time I was helping them add PHP + Apache support to Elastic Beanstalk in time for launch, as I was the _de-facto_ “PHP guy” in AWS.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/etc-passwd@2x.jpg\" alt=\"/etc/passwd\"\u003e}}\n\nDevelopment was running on a pre-release version of what would become [Amazon Linux]({{% wayback \"https://aws.amazon.com/amazon-linux-ami/\" %}}). The original configuration was designed to run `yum -y update` on boot, which essentially means _pick up the latest versions of all installed packages_. While the team was thinking about system security (and avoiding outdated packages), everything broke on the day that the Amazon Linux team published a new version of Apache with backwards-incompatible changes. The development team **failed to understand trust**.\n\nFortunately, it was a little before the public launch, and so only a few internal beta customers and developers were impacted. But watching that incident was the day that I learned that you don't _arbitrarily_ install all system updates. You should do that in your development environment instead, work out the issues, then roll something out to Production that has been tested and works as expected.\n\n### Dev/Prod parity\n\nIf you've never heard of the [12-factor app methodology]({{% wayback \"https://www.12factor.net\" %}}), you are absolutely missing out. One of the chapters is entitled “[Dev/prod parity]({{% wayback \"https://www.12factor.net/dev-prod-parity\" %}})”, which essentially boils down to _keeping development, staging, and production as similar as possible_.\n\nOne thing that I've seen bite a team is that they were deploying an application by pushing the source code from Git to the production instances, then resolving their packages _directly on the instance_. (To be fair, this was back in the days when [Capistrano]({{% wayback \"https://capistranorb.com\" %}}) was hot, and we've come a long way since then.)\n\nBut even in the world of Docker and _continuous integration_, I still see similar things happen. A team will build a Docker image for their dev app in their CI pipeline, push it to their Docker repository, then deploy it to dev. Then they build the image again when deploying to staging. Then again when they deploy to Prod. **This is the same problem!** The dependencies are not being tested appropriately in the earlier environments before progressing to the production environment.\n\nWith Docker, some teams have figured out how to make the exact same mistakes even faster! Those teams have **failed to understand trust**.\n\nInstead, you should build the production-ready Docker image _once_, then promote that same image up to each environment as the requisite confidence is built.\n\n“But how do I include my development dependencies inside my Docker container?”\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/batman-slap-docker-dev@2x.jpg\" alt=\"Batman slaps Robin\"\u003e}}\n\nDocker images that are built should be the exact same bytes, regardless of the environment. Your dev build should write out logs in the same way as your Production app would (although perhaps to a local location). You should be able to define things like environment variables that are read by the Docker daemon at container launch. Or by defining a local volume to mount containing configuration information. But the insides of the Docker image should always be completely identical between environments.\n\n## Guidelines for trust\n\nWhen you're provisioning software onto a machine that will run in Production, you don't want to be running software from _anywhere_. You need to know that you can _trust_ the source of the software before you ship it into Production.\n\nIn my case, I tend to work on teams which run servers with a blend of RedHat Enterprise Linux (RHEL), CentOS, and Amazon Linux. Containers are commonly Ubuntu, Debian, or Alpine. I work with applications written in nearly every major programming language. These are my criteria for determining whether or not to trust a package or Docker image.\n\n1. Packages are maintained by CentOS, RedHat, Amazon, Ubuntu, Debian, Alpine, etc., directly.\n\n1. Packages are maintained by the vendor of the software directly (e.g., Docker, Amazon, PHP, Node Foundation, Angular, Kubernetes).\n\n1. Packages are maintained by a reputable third-party source (as few of these as possible; e.g., [NodeSource](https://github.com/nodesource/distributions)).\n\n1. Packages are maintained by us. That is, we compile them from source ourselves (into `.rpm`, `.deb`, or `.apk` packages), or we write the software packages ourselves (e.g., `composer`, `pip`, `npm`, `dep`).\n\nYour criteria may look different, and that's OK. Some engineering teams are better at this, while others are still maturing.\n\nIf you don't have criteria, and generally just install software from anywhere, I have two pieces of advice.\n\n1. Stop it.\n\n1. Our criteria has been very good to us. Feel free to borrow ours.\n"},
    "links": {
        "prev": {"title": "The Hiring Process, Part I", "permalink": "https://ryanparman.com/posts/2018/the-hiring-process-part-i-what-i-look-for-in-a-cv-resume-remastered/"},
        "next": {"title": "Playlist: Best of P.O.D.", "permalink": "https://ryanparman.com/posts/2019/playlist-best-of-pod/"},
        "ignore": "me"
    }
}

            
            , {
    "kind": "page",
    "title": "Creating Smaller Docker Containers for Your Apps",
    "description": "When it comes to Docker containers, the smaller, the better.",
    "summary": {
        "content": "When it comes to Docker containers, the smaller, the better. Smaller containers are easier to work with, deploy faster, and tend to have fewer security vulnerabilities. This piece is part of a larger series on Engineering for Site Reliability, specifically Docker. Big is Bad I worked at WePay during the transition from a monolithic application in the datacenter to a series of microservices running in the cloud. I spent a lot of time working on the Vagrant-based CentOS development environment for the monolith, and also started maintaining a custom CentOS base image in Google Cloud.",
        "isTruncated": true
    },
    "published": "2018-08-16T16:27:52Z",
    "updated": "2019-02-10T21:35:12-08:00",
    "permalink": "https://ryanparman.com/posts/2018/creating-smaller-docker-containers-for-your-apps/",
    "relativePermalink": "/posts/2018/creating-smaller-docker-containers-for-your-apps/",
    "aliases": ["/2018/08/16/creating-very-small-docker-containers-for-php-apps"],
    "images": ["https://cdn.ryanparman.com/hugo/posts/2018/docker-logo.jpg", "https://cdn.ryanparman.com/hugo/headers/docker/dockerconeu.jpg"],
    "videos": [],
    "categories": ["Engineering for Site Reliability"],
    "tags": ["docker", "alpine linux", "centos", "ubuntu", "php", "nginx", "composer", "pip", "npm", "java", "glibc", "musl", "cve"],
    "series": ["Engineering for Site Reliability"],
    "keywords": [],
    "meta": {
        "wordCount": 1980,
        "readingTime": "10 minutes",
        "language": "en",
        "isDraft": false,
        "isHome": false,
        "isNode": false,
        "isPage": true,
        "isTranslated": false
    },
    "sourceFile": {
        "path": "posts/2018/20180816-creating-smaller-docker-containers-for-your-apps.md",
        "logicalName": "20180816-creating-smaller-docker-containers-for-your-apps.md",
        "translationBaseName": "20180816-creating-smaller-docker-containers-for-your-apps",
        "baseFileName": "20180816-creating-smaller-docker-containers-for-your-apps",
        "ext": "md",
        "lang": "en",
        "dir": "posts/2018/"
    },
    "content": {
        "tableOfContents": "\u003cnav id=\"TableOfContents\"\u003e\n  \u003cul\u003e\n    \u003cli\u003e\u003ca href=\"#big-is-bad\"\u003eBig is Bad\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#smaller-is-better\"\u003eSmaller is better\u003c/a\u003e\n      \u003cul\u003e\n        \u003cli\u003e\u003ca href=\"#use-alpine-linux\"\u003eUse Alpine Linux\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#learn-to-love-the-layer-cache\"\u003eLearn to love the layer cache\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#installed-dependencies-should-be-runtime-only\"\u003eInstalled dependencies should be runtime-only\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#flattening-your-base-images\"\u003eFlattening your (base) images\u003c/a\u003e\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#reduced-security-vulnerabilities\"\u003eReduced security vulnerabilities\u003c/a\u003e\u003c/li\u003e\n    \u003cli\u003e\u003ca href=\"#conclusion\"\u003eConclusion\u003c/a\u003e\u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/nav\u003e",
        "html":"\u003cp itemprop=\"description\" class=\"f5 f4-m f3-l mt0 lh-copy p-summary entry-summary\"\u003e\nWhen it comes to Docker containers, the smaller, the better. Smaller containers are easier to work with, deploy faster, and tend to have fewer security vulnerabilities.\n\u003c/p\u003e\n\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/docker-logo.jpg\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\n\u003caside class=\"age aside container flex\"\u003e\u003cp\u003eThis piece is part of a larger series on \u003ca href=\"/series/engineering-for-site-reliability/\"\u003eEngineering for Site Reliability\u003c/a\u003e, specifically \u003cem\u003eDocker\u003c/em\u003e.\u003c/p\u003e\n\u003c/aside\u003e\n\n\u003ch2 id=\"big-is-bad\"\u003eBig is Bad\u003c/h2\u003e\n\u003cp\u003eI worked at \u003ca href=\"https://wepay.com\"\u003eWePay\u003c/a\u003e during the transition from a monolithic application in the datacenter to a series of microservices running in the cloud. I spent a lot of time working on the Vagrant-based CentOS development environment for the monolith, and also started maintaining a custom CentOS base image in Google Cloud.\u003c/p\u003e\n\u003cp\u003eAs we were all learning about Docker, images, containers, and how it all worked together, the director of DevOps declared (unilaterally) that we should create Docker base images for the various languages we were using (PHP, Python, Java, Go), and they should all be built on a core CentOS 7 Docker image.\u003c/p\u003e\n\u003cp\u003eNow, many parts of this make sense:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eHaving a base disk image for our hosts that builds-in all of the shared functionality we needed.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHaving a base Docker image that every application referenced with \u003ccode\u003eFROM\u003c/code\u003e in their \u003ccode\u003eDockerfiles\u003c/code\u003e which included shared patterns for logging and metrics.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHaving an optimized image for specific languages made it easier for developers using those languages to rapidly spin-up new application containers.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBut there were also some major drawbacks to this approach.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eDevelopers wanted to run \u003ccode\u003ecomposer install\u003c/code\u003e and \u003ccode\u003epip install requirements.txt\u003c/code\u003e from \u003cem\u003einside the container\u003c/em\u003e. This often required \u003cem\u003edevelopment dependencies\u003c/em\u003e to be installed in the containers.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOne of our Java micro-service applications (CentOS 7 + Oracle Java + application code + development dependencies) clocked in at \u003cstrong\u003e1.8 GB\u003c/strong\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOur build system was frequently buckling under the weight of caching and transferring large Docker images between its cluster and our Artifactory installation.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/fat-guy.jpg\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eNow, some of this can be chalked up to learning a new technology. Some of these are growing pains that were incurred at the same time as chunking apart our monolithic PHP app into Java/Python/Golang microservices. Some of this was hubris by people who made unilateral decisions. But we\u0026rsquo;d made it to the cloud. We\u0026rsquo;d made it to microservices. And I\u0026rsquo;m sure that WePay\u0026rsquo;s development practices have improved greatly over the last couple of years since I left.\u003c/p\u003e\n\u003ch2 id=\"smaller-is-better\"\u003eSmaller is better\u003c/h2\u003e\n\u003cp\u003eIn my current gig, my team has gone all-in with Docker, the AWS cloud, Infrastructure-as-Code, CI/CD practices, and the SRE support model. I\u0026rsquo;ll spend some time talking about these other topics in a future post, but I do want to talk about some process magic that makes it nearly effortless to deploy to Production multiple times per day with exceptionally little stress.\u003c/p\u003e\n\u003ch3 id=\"use-alpine-linux\"\u003eUse Alpine Linux\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://alpinelinux.org\"\u003eAlpine Linux\u003c/a\u003e is the \u003cstrong\u003e5 MB\u003c/strong\u003e successor to \u003ca href=\"https://www.busybox.net\"\u003eBusybox\u003c/a\u003e, which provides a few additional tools to Busybox’s \u003cstrong\u003e2 MB\u003c/strong\u003e image size.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/alpine.png\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eGenerally speaking, \u003cstrong\u003eyou should always use Alpine Linux\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eI use the word \u0026ldquo;generally\u0026rdquo; because there are certain exceptions to this (otherwise) strong recommendation. The most important of which is that while larger Linux distributions which use the GNU’s \u003ca href=\"https://www.gnu.org/software/libc/\"\u003eglibc\u003c/a\u003e library for the C Standard Library implementation, Alpine, Busybox, and others use a different library called \u003ca href=\"https://musl-libc.org\"\u003emusl\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can take a look at the \u003ca href=\"https://wiki.musl-libc.org/functional-differences-from-glibc.html\"\u003edifferences between musl and glibc\u003c/a\u003e, but the part that matters to you is that there is \u003cem\u003esome\u003c/em\u003e software that exists which depends on the non-standard parts of glibc that haven\u0026rsquo;t been implemented in musl yet. What this means, practically speaking, are that things like the \u003ca href=\"https://bugs.php.net/74982\"\u003e\u003ccode\u003e%P\u003c/code\u003e marker for \u003ccode\u003estrftime()\u003c/code\u003e doesn\u0026rsquo;t work as documented\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"learn-to-love-the-layer-cache\"\u003eLearn to love the layer cache\u003c/h3\u003e\n\u003cp\u003eDocker images use \u003cem\u003elayers\u003c/em\u003e to overlay newer changes over previous changes using a technology called \u003ca href=\"https://en.wikipedia.org/wiki/UnionFS\"\u003eUnionFS\u003c/a\u003e. This works similarly to Git, where all of the changes that ever happened are still inside the repository, but when you pull the \u003ccode\u003emaster\u003c/code\u003e branch, you\u0026rsquo;re pulling down dozens (or \u003cem\u003ehundreds\u003c/em\u003e, or \u003cem\u003ethousands\u003c/em\u003e) of layers that all need to resolve into the current state of the branch.\u003c/p\u003e\n\u003cp\u003eWith Docker, each of these layers is introduced by the \u003ca href=\"https://docs.docker.com/engine/reference/builder/#run\"\u003e\u003ccode\u003eRUN\u003c/code\u003e statement\u003c/a\u003e inside a \u003ccode\u003eDockerfile\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-Dockerfile\" data-lang=\"Dockerfile\"\u003e\u003cspan style=\"color:#66d9ef\"\u003eFROM\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e nginx:1.15.1-alpine\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eENV\u003c/span\u003e RUNTIME_DEPS ca-certificates curl\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e echo \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;http://dl-cdn.alpinelinux.org/alpine/v3.7/main\u0026#34;\u003c/span\u003e \u0026gt;\u0026gt; /etc/apk/repositories\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e apk upgrade --no-cache --update\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e apk add --no-cache --virtual .runtime-deps $RUNTIME_DEPS\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e chmod -Rf \u003cspan style=\"color:#ae81ff\"\u003e0777\u003c/span\u003e /var/log\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e...\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eIf a change is made to an earlier layer, then the layer cache is invalidated for all of the later layers, and those later layers need to be rebuilt. (Because of this, it\u0026rsquo;s always a good idea to put \u003cem\u003einfrequently\u003c/em\u003e changed commands first, and \u003cem\u003emore frequently\u003c/em\u003e changed commands last.)\u003c/p\u003e\n\u003cp\u003eUnfortunately, many people (including myself) read that Docker image layers have filesize overhead built into them. In order to make your containers smaller, you should combine all of your commands into a single \u003ccode\u003eRUN\u003c/code\u003e statement. The side effect is that any time you need to change \u003cem\u003eanything\u003c/em\u003e inside that \u003ccode\u003eRUN\u003c/code\u003e statement, Docker needs to rebuild everything from scratch — since it\u0026rsquo;s all in the same layer (which changed).\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-Dockerfile\" data-lang=\"Dockerfile\"\u003e\u003cspan style=\"color:#66d9ef\"\u003eFROM\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e nginx:1.15.1-alpine\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eENV\u003c/span\u003e RUNTIME_DEPS ca-certificates curl\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e echo \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;http://dl-cdn.alpinelinux.org/alpine/v3.7/main\u0026#34;\u003c/span\u003e \u0026gt;\u0026gt; /etc/apk/repositories \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    apk upgrade --no-cache --update \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    apk add --no-cache --virtual .runtime-deps $RUNTIME_DEPS \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    chmod -Rf \u003cspan style=\"color:#ae81ff\"\u003e0777\u003c/span\u003e /var/log\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e...\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eBy leveraging the \u003ccode\u003eRUN\u003c/code\u003e statement as it was intended, you get to take advantage of faster re-build times by leveraging the \u003cem\u003elayer cache\u003c/em\u003e. This means that any layers (e.g., \u003ccode\u003eRUN\u003c/code\u003e statements) which haven\u0026rsquo;t changed since the last build do not need to be built again!\u003c/p\u003e\n\u003cp\u003eYes, your \u003cem\u003edevelopment\u003c/em\u003e Docker image may be a little larger, but we will address this later in this post.\u003c/p\u003e\n\u003ch3 id=\"installed-dependencies-should-be-runtime-only\"\u003eInstalled dependencies should be runtime-only\u003c/h3\u003e\n\u003cp\u003eThis is the one that kills me the most because it can be so wasteful, and it stems from not understanding how to use the tools in your toolbox.\u003c/p\u003e\n\u003cp\u003eFirstly, use a \u003ca href=\"https://docs.docker.com/engine/reference/builder/#dockerignore-file\"\u003e\u003ccode\u003e.dockerignore\u003c/code\u003e file\u003c/a\u003e. Again, this is very similar to how a \u003ccode\u003e.gitignore\u003c/code\u003e file works — you don\u0026rsquo;t need everything you use for development to end up inside your Docker image, so use \u003ccode\u003e.dockerignore\u003c/code\u003e to avoid development dependencies.\u003c/p\u003e\n\u003cp\u003eYou never need your \u003ccode\u003e.git/\u003c/code\u003e directory to be copied into a Docker image. Once you\u0026rsquo;ve resolved your application dependencies, you also don\u0026rsquo;t need your \u003ccode\u003ecomposer.json\u003c/code\u003e, \u003ccode\u003epackage.json\u003c/code\u003e, \u003ccode\u003erequirements.txt\u003c/code\u003e, or other package manager definitions in there. You only need your vendored code. (Even then, you don\u0026rsquo;t need the tests for the vendored code either, most of the time. You should ignore those as well.)\u003c/p\u003e\n\u003cp\u003eSome dependencies need to build binaries for the OS they\u0026rsquo;re running inside of. For example, Node.js apps often rely on \u003cem\u003eOniguruma\u003c/em\u003e. Many Python applications rely on \u003cem\u003eMySQLdb\u003c/em\u003e. Both of these require that you install compilation tools and compile them on the OS that they run in.\u003c/p\u003e\n\u003cp\u003eSome companies solve this problem by \u003cem\u003einstalling GCC inside the Docker image\u003c/em\u003e.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns\"\u003e\n\t\u003camp-img src=\"https://cdn.ryanparman.com/hugo/posts/2018/mcfly-confused.gif\" layout=\"responsive\" width=\"\" height=\"\"\u003e\u003c/amp-img\u003e\n    \u003cp class=\"f6 gray tc db\"\u003e\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eA better solution is to have \u003cem\u003ebuild-time\u003c/em\u003e and \u003cem\u003erun-time\u003c/em\u003e dependencies, wherein you uninstall the build-time dependencies once you\u0026rsquo;re done with them.\u003c/p\u003e\n\u003cp\u003eHere is an example of a PHP app that includes Redis support and installs the New Relic agent extension.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-Dockerfile\" data-lang=\"Dockerfile\"\u003e\u003cspan style=\"color:#66d9ef\"\u003eFROM\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e php:7.2.8-fpm-alpine3.7\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Needed at build-time, then can be uninstalled.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eENV\u003c/span\u003e BUILD_DEPS alpine-sdk coreutils wget git autoconf re2c\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Should remain inside the container for runtime purposes.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eENV\u003c/span\u003e PERSISTENT_DEPS net-tools hiredis-dev gmp-dev\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# PHP extensions to install.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eENV\u003c/span\u003e INSTALL_EXTENSIONS gmp json opcache pdo pdo_mysql\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# New Relic values.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eENV\u003c/span\u003e NR_INSTALL_SILENT \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eENV\u003c/span\u003e NR_VERSION 8.0.0.204\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Update the packages in the container to their latest security patches.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e apk upgrade --no-cache --update\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Install your build-time and runtime dependencies.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Give these groups of dependencies names like `.build-deps`\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# and `.persistent-deps` that we can refer to later.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e apk add --no-cache --virtual .build-deps $BUILD_DEPS\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e apk add --no-cache --virtual .persistent-deps $PERSISTENT_DEPS\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Install the PHP extensions we need from the PHP repository.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# https://github.com/php/php-src/tree/master/ext\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e docker-php-ext-install $INSTALL_EXTENSIONS\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Install the New Relic agent extension for PHP.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e wget -O /tmp/newrelic-php5.tar.gz https://download.newrelic.com/php_agent/archive/$NR_VERSION/newrelic-php5-$NR_VERSION-linux-musl.tar.gz\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e tar -zxvf /tmp/newrelic-php5.tar.gz -C /usr/local/lib\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e /usr/local/lib/newrelic*/newrelic-install install\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e rm /usr/local/etc/php/conf.d/newrelic.ini\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Install the phpiredis extension for PHP.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e git clone https://github.com/nrk/phpiredis.git \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e cd phpiredis \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e phpize \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e ./configure --enable-phpiredis \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e make \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e make install\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e# Uninstall the grouping of dependencies called `.build-deps`.\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eRUN\u003c/span\u003e apk del .build-deps\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\u003c/span\u003e...\u003cspan style=\"color:#960050;background-color:#1e0010\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"flattening-your-base-images\"\u003eFlattening your (base) images\u003c/h3\u003e\n\u003cp\u003eFlattening your images is an extra step that you can take to make your images as small as possible. This is particularly useful if you are building/providing \u003cem\u003ebase\u003c/em\u003e images for other people to consume downstream.\u003c/p\u003e\n\u003cp\u003eAs Thomas Uhrig \u003ca href=\"https://tuhrig.de/flatten-a-docker-container-or-image/\"\u003ewrites\u003c/a\u003e:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWe can use this mechanism to flatten and shrink a Docker container. If we save an image to the disk, its whole history will be preserved, but if we export a container, its history gets lost and the resulting tarball will be much smaller.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"color:#75715e\"\u003e# Launch the container from a Docker image\u003c/span\u003e\ndocker run \u0026lt;image\u0026gt; --detach\n\n\u003cspan style=\"color:#75715e\"\u003e# Export the running container to a tarball\u003c/span\u003e\ndocker export \u0026lt;container\u0026gt; \u0026gt; /tmp/docker-image.tar\n \n\u003cspan style=\"color:#75715e\"\u003e# Import it back into Docker\u003c/span\u003e\ncat /tmp/docker-image.tar | docker import - php-fpm:without-layers\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eBy running a container and exporting the data as a tarball, you can remove all of the intermediate layers and history from the final image, removing filesize overhead and reducing the overall image size.\u003c/p\u003e\n\u003cp\u003eAt the time of this writing, the latest version of \u003ca href=\"https://store.docker.com/images/php\"\u003ePHP is 7.2.8\u003c/a\u003e (actually, 7.2.9 was cut yesterday, but the updated image hasn\u0026rsquo;t been released yet), which builds on top of the \u003ca href=\"https://store.docker.com/images/alpine\"\u003eAlpine Linux 3.7\u003c/a\u003e image.\u003c/p\u003e\n\u003cp\u003eThe Alpine Linux image clocks in at just under \u003cstrong\u003e5 MB\u003c/strong\u003e. The PHP image adds a few layers, and brings things up to \u003cstrong\u003e78 MB\u003c/strong\u003e. So far, both of these are smaller than the base CentOS or Ubuntu images.\u003c/p\u003e\n\u003cp\u003eOur application includes the New Relic agent for PHP, a few extensions, our application code, and our Composer \u003ccode\u003evendor\u003c/code\u003e directory (without dev-dependencies).\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003ecomposer install --prefer-dist --no-dev\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eWe \u003cem\u003eshould\u003c/em\u003e remove things like tests from our \u003ccode\u003evendor\u003c/code\u003e directory, but we haven\u0026rsquo;t done that yet at the time of this writing. With all of our (wonderfully cached) layers, this brings the decompressed image size to \u003cstrong\u003e408 MB\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eAfter stripping out the history and removing all of the individual layers from the image (via a process called \u003cem\u003eflattening\u003c/em\u003e), our final \u003cem\u003edecompressed\u003c/em\u003e image size is a mere \u003cstrong\u003e197 MB\u003c/strong\u003e in size.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-plain\" data-lang=\"plain\"\u003e$ docker images\n\nREPOSITORY     TAG                   IMAGE ID       CREATED          SIZE\nalpine         3.7                   791c3e2ebfcb   5 weeks ago      4.2MB\nphp            7.2.7-fpm-alpine3.7   9cf17fea14c0   5 weeks ago      78.3MB\nphp-fpm        with-layers           94121f6a6537   29 seconds ago   408MB\nphp-fpm        without-layers        8468ea1ee874   4 seconds ago    197MB\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eWhen you push your image up to a Docker registry (e.g., Docker Hub, Amazon ECR, Google Container Registry, Quay.io, Artifactory), the images will be compressed. Our final Docker image, compressed-at-rest, is only \u003cstrong\u003e72 MB\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eA small, 72 MB Docker image for our application is small and easy enough to push into our CI/CD pipeline in only a few seconds, and puts very little network or storage strain on our internal systems. It\u0026rsquo;s fast to download into my local development environment, and every step of the development and build processes are automated.\u003c/p\u003e\n\u003ch2 id=\"reduced-security-vulnerabilities\"\u003eReduced security vulnerabilities\u003c/h2\u003e\n\u003cp\u003eOver my career, I\u0026rsquo;ve observed that engineers view the topic of \u0026ldquo;security\u0026rdquo; primarily through the lense of their job role.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eApplication engineers tend to view security as things like XSS vulnerabilities and SQL injections.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSystem engineers tend to view security as things like CVEs and intrusions.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSecurity engineers tend to see those things + TLS certificates + CIS Benchmarks + secrets management and rotation + user permissions + …\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this context, I\u0026rsquo;m referring primarily to \u003cem\u003esecurity vulnerabilties\u003c/em\u003e along the lines of \u003ca href=\"http://heartbleed.com\"\u003eHeartbleed\u003c/a\u003e, \u003ca href=\"https://nvd.nist.gov/vuln/detail/CVE-2014-6271\"\u003eShellShock\u003c/a\u003e, and \u003ca href=\"https://httpoxy.org\"\u003ehttpoxy\u003c/a\u003e. Because there is so little software installed by default, the \u003cem\u003eattack surface\u003c/em\u003e is substantially reduced — oftentimes to the point where there are zero known vulnerabilities anywhere in your application container.\u003c/p\u003e\n\u003cdiv class=\"pa2-ns pv4-l\"\u003e\n    \u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://cdn.ryanparman.com/hugo/posts/2018/heartbleed.webp\" alt=\"Logo for the Heartbleed vulnerability.\" class=\"db fullimage-noshadow\" decoding=\"async\" style=\"margin-left: auto; margin-right: auto; \"\u003e\n        \u003cimg src=\"https://cdn.ryanparman.com/hugo/posts/2018/heartbleed.png\" alt=\"Logo for the Heartbleed vulnerability.\" class=\"db fullimage-noshadow\" decoding=\"async\" style=\"margin-left: auto; margin-right: auto; \"\u003e\n    \u003c/picture\u003e\n    \u003cp class=\"f6 gray tc db\"\u003eLogo for the Heartbleed vulnerability.\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp\u003eThis is entirely unheard of in CentOS, Ubuntu, and other larger distributions. As a matter of fact, when our application went live and we underwent review with the security team, they scanned our hosts and containers with zero unpatched vulnerabilities and thought that the scan was bad or their software was broken.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eThe most important things to take away from this are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eBig Docker images are a bad thing.\u003c/li\u003e\n\u003cli\u003eUse Alpine Linux. Seriously.\u003c/li\u003e\n\u003cli\u003eRemove your build-time dependencies.\u003c/li\u003e\n\u003cli\u003eFlatten your images if you\u0026rsquo;re sharing them.\u003c/li\u003e\n\u003cli\u003eThe less software that is installed, the fewer security vulnerabilities there will be.\u003c/li\u003e\n\u003cli\u003eMaking your images as small as possible can greatly reduce the burden on the rest of your infrastructure.\u003c/li\u003e\n\u003c/ol\u003e\n",
        "plain":"When it comes to Docker containers, the smaller, the better. Smaller containers are easier to work with, deploy faster, and tend to have fewer security vulnerabilities.   This piece is part of a larger series on Engineering for Site Reliability, specifically Docker.\n Big is Bad I worked at WePay during the transition from a monolithic application in the datacenter to a series of microservices running in the cloud. I spent a lot of time working on the Vagrant-based CentOS development environment for the monolith, and also started maintaining a custom CentOS base image in Google Cloud.\nAs we were all learning about Docker, images, containers, and how it all worked together, the director of DevOps declared (unilaterally) that we should create Docker base images for the various languages we were using (PHP, Python, Java, Go), and they should all be built on a core CentOS 7 Docker image.\nNow, many parts of this make sense:\n  Having a base disk image for our hosts that builds-in all of the shared functionality we needed.\n  Having a base Docker image that every application referenced with FROM in their Dockerfiles which included shared patterns for logging and metrics.\n  Having an optimized image for specific languages made it easier for developers using those languages to rapidly spin-up new application containers.\n  But there were also some major drawbacks to this approach.\n  Developers wanted to run composer install and pip install requirements.txt from inside the container. This often required development dependencies to be installed in the containers.\n  One of our Java micro-service applications (CentOS 7 + Oracle Java + application code + development dependencies) clocked in at 1.8 GB.\n  Our build system was frequently buckling under the weight of caching and transferring large Docker images between its cluster and our Artifactory installation.\n    Now, some of this can be chalked up to learning a new technology. Some of these are growing pains that were incurred at the same time as chunking apart our monolithic PHP app into Java/Python/Golang microservices. Some of this was hubris by people who made unilateral decisions. But we\u0026rsquo;d made it to the cloud. We\u0026rsquo;d made it to microservices. And I\u0026rsquo;m sure that WePay\u0026rsquo;s development practices have improved greatly over the last couple of years since I left.\nSmaller is better In my current gig, my team has gone all-in with Docker, the AWS cloud, Infrastructure-as-Code, CI/CD practices, and the SRE support model. I\u0026rsquo;ll spend some time talking about these other topics in a future post, but I do want to talk about some process magic that makes it nearly effortless to deploy to Production multiple times per day with exceptionally little stress.\nUse Alpine Linux Alpine Linux is the 5 MB successor to Busybox, which provides a few additional tools to Busybox’s 2 MB image size.\n  Generally speaking, you should always use Alpine Linux.\nI use the word \u0026ldquo;generally\u0026rdquo; because there are certain exceptions to this (otherwise) strong recommendation. The most important of which is that while larger Linux distributions which use the GNU’s glibc library for the C Standard Library implementation, Alpine, Busybox, and others use a different library called musl.\nYou can take a look at the differences between musl and glibc, but the part that matters to you is that there is some software that exists which depends on the non-standard parts of glibc that haven\u0026rsquo;t been implemented in musl yet. What this means, practically speaking, are that things like the %P marker for strftime() doesn\u0026rsquo;t work as documented.\nLearn to love the layer cache Docker images use layers to overlay newer changes over previous changes using a technology called UnionFS. This works similarly to Git, where all of the changes that ever happened are still inside the repository, but when you pull the master branch, you\u0026rsquo;re pulling down dozens (or hundreds, or thousands) of layers that all need to resolve into the current state of the branch.\nWith Docker, each of these layers is introduced by the RUN statement inside a Dockerfile.\nFROMnginx:1.15.1-alpineENV RUNTIME_DEPS ca-certificates curlRUN echo \u0026#34;http://dl-cdn.alpinelinux.org/alpine/v3.7/main\u0026#34; \u0026gt;\u0026gt; /etc/apk/repositoriesRUN apk upgrade --no-cache --updateRUN apk add --no-cache --virtual .runtime-deps $RUNTIME_DEPSRUN chmod -Rf 0777 /var/log...If a change is made to an earlier layer, then the layer cache is invalidated for all of the later layers, and those later layers need to be rebuilt. (Because of this, it\u0026rsquo;s always a good idea to put infrequently changed commands first, and more frequently changed commands last.)\nUnfortunately, many people (including myself) read that Docker image layers have filesize overhead built into them. In order to make your containers smaller, you should combine all of your commands into a single RUN statement. The side effect is that any time you need to change anything inside that RUN statement, Docker needs to rebuild everything from scratch — since it\u0026rsquo;s all in the same layer (which changed).\nFROMnginx:1.15.1-alpineENV RUNTIME_DEPS ca-certificates curlRUN echo \u0026#34;http://dl-cdn.alpinelinux.org/alpine/v3.7/main\u0026#34; \u0026gt;\u0026gt; /etc/apk/repositories \u0026amp;\u0026amp; \\  apk upgrade --no-cache --update \u0026amp;\u0026amp; \\  apk add --no-cache --virtual .runtime-deps $RUNTIME_DEPS \u0026amp;\u0026amp; \\  chmod -Rf 0777 /var/log...By leveraging the RUN statement as it was intended, you get to take advantage of faster re-build times by leveraging the layer cache. This means that any layers (e.g., RUN statements) which haven\u0026rsquo;t changed since the last build do not need to be built again!\nYes, your development Docker image may be a little larger, but we will address this later in this post.\nInstalled dependencies should be runtime-only This is the one that kills me the most because it can be so wasteful, and it stems from not understanding how to use the tools in your toolbox.\nFirstly, use a .dockerignore file. Again, this is very similar to how a .gitignore file works — you don\u0026rsquo;t need everything you use for development to end up inside your Docker image, so use .dockerignore to avoid development dependencies.\nYou never need your .git/ directory to be copied into a Docker image. Once you\u0026rsquo;ve resolved your application dependencies, you also don\u0026rsquo;t need your composer.json, package.json, requirements.txt, or other package manager definitions in there. You only need your vendored code. (Even then, you don\u0026rsquo;t need the tests for the vendored code either, most of the time. You should ignore those as well.)\nSome dependencies need to build binaries for the OS they\u0026rsquo;re running inside of. For example, Node.js apps often rely on Oniguruma. Many Python applications rely on MySQLdb. Both of these require that you install compilation tools and compile them on the OS that they run in.\nSome companies solve this problem by installing GCC inside the Docker image.\n  A better solution is to have build-time and run-time dependencies, wherein you uninstall the build-time dependencies once you\u0026rsquo;re done with them.\nHere is an example of a PHP app that includes Redis support and installs the New Relic agent extension.\nFROMphp:7.2.8-fpm-alpine3.7# Needed at build-time, then can be uninstalled.ENV BUILD_DEPS alpine-sdk coreutils wget git autoconf re2c# Should remain inside the container for runtime purposes.ENV PERSISTENT_DEPS net-tools hiredis-dev gmp-dev# PHP extensions to install.ENV INSTALL_EXTENSIONS gmp json opcache pdo pdo_mysql# New Relic values.ENV NR_INSTALL_SILENT 1ENV NR_VERSION 8.0.0.204# Update the packages in the container to their latest security patches.RUN apk upgrade --no-cache --update# Install your build-time and runtime dependencies.# Give these groups of dependencies names like `.build-deps`# and `.persistent-deps` that we can refer to later.RUN apk add --no-cache --virtual .build-deps $BUILD_DEPSRUN apk add --no-cache --virtual .persistent-deps $PERSISTENT_DEPS# Install the PHP extensions we need from the PHP repository.# https://github.com/php/php-src/tree/master/extRUN docker-php-ext-install $INSTALL_EXTENSIONS# Install the New Relic agent extension for PHP.RUN wget -O /tmp/newrelic-php5.tar.gz https://download.newrelic.com/php_agent/archive/$NR_VERSION/newrelic-php5-$NR_VERSION-linux-musl.tar.gzRUN tar -zxvf /tmp/newrelic-php5.tar.gz -C /usr/local/libRUN /usr/local/lib/newrelic*/newrelic-install installRUN rm /usr/local/etc/php/conf.d/newrelic.ini# Install the phpiredis extension for PHP.RUN git clone https://github.com/nrk/phpiredis.git \u0026amp;\u0026amp; cd phpiredis \u0026amp;\u0026amp; phpize \u0026amp;\u0026amp; ./configure --enable-phpiredis \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install# Uninstall the grouping of dependencies called `.build-deps`.RUN apk del .build-deps...Flattening your (base) images Flattening your images is an extra step that you can take to make your images as small as possible. This is particularly useful if you are building/providing base images for other people to consume downstream.\nAs Thomas Uhrig writes:\n We can use this mechanism to flatten and shrink a Docker container. If we save an image to the disk, its whole history will be preserved, but if we export a container, its history gets lost and the resulting tarball will be much smaller.\n # Launch the container from a Docker image docker run \u0026lt;image\u0026gt; --detach # Export the running container to a tarball docker export \u0026lt;container\u0026gt; \u0026gt; /tmp/docker-image.tar # Import it back into Docker cat /tmp/docker-image.tar | docker import - php-fpm:without-layers By running a container and exporting the data as a tarball, you can remove all of the intermediate layers and history from the final image, removing filesize overhead and reducing the overall image size.\nAt the time of this writing, the latest version of PHP is 7.2.8 (actually, 7.2.9 was cut yesterday, but the updated image hasn\u0026rsquo;t been released yet), which builds on top of the Alpine Linux 3.7 image.\nThe Alpine Linux image clocks in at just under 5 MB. The PHP image adds a few layers, and brings things up to 78 MB. So far, both of these are smaller than the base CentOS or Ubuntu images.\nOur application includes the New Relic agent for PHP, a few extensions, our application code, and our Composer vendor directory (without dev-dependencies).\ncomposer install --prefer-dist --no-dev We should remove things like tests from our vendor directory, but we haven\u0026rsquo;t done that yet at the time of this writing. With all of our (wonderfully cached) layers, this brings the decompressed image size to 408 MB.\nAfter stripping out the history and removing all of the individual layers from the image (via a process called flattening), our final decompressed image size is a mere 197 MB in size.\n$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE alpine 3.7 791c3e2ebfcb 5 weeks ago 4.2MB php 7.2.7-fpm-alpine3.7 9cf17fea14c0 5 weeks ago 78.3MB php-fpm with-layers 94121f6a6537 29 seconds ago 408MB php-fpm without-layers 8468ea1ee874 4 seconds ago 197MB When you push your image up to a Docker registry (e.g., Docker Hub, Amazon ECR, Google Container Registry, Quay.io, Artifactory), the images will be compressed. Our final Docker image, compressed-at-rest, is only 72 MB.\nA small, 72 MB Docker image for our application is small and easy enough to push into our CI/CD pipeline in only a few seconds, and puts very little network or storage strain on our internal systems. It\u0026rsquo;s fast to download into my local development environment, and every step of the development and build processes are automated.\nReduced security vulnerabilities Over my career, I\u0026rsquo;ve observed that engineers view the topic of \u0026ldquo;security\u0026rdquo; primarily through the lense of their job role.\n  Application engineers tend to view security as things like XSS vulnerabilities and SQL injections.\n  System engineers tend to view security as things like CVEs and intrusions.\n  Security engineers tend to see those things + TLS certificates + CIS Benchmarks + secrets management and rotation + user permissions + …\n  In this context, I\u0026rsquo;m referring primarily to security vulnerabilties along the lines of Heartbleed, ShellShock, and httpoxy. Because there is so little software installed by default, the attack surface is substantially reduced — oftentimes to the point where there are zero known vulnerabilities anywhere in your application container.\n Logo for the Heartbleed vulnerability.\n This is entirely unheard of in CentOS, Ubuntu, and other larger distributions. As a matter of fact, when our application went live and we underwent review with the security team, they scanned our hosts and containers with zero unpatched vulnerabilities and thought that the scan was bad or their software was broken.\nConclusion The most important things to take away from this are:\n Big Docker images are a bad thing. Use Alpine Linux. Seriously. Remove your build-time dependencies. Flatten your images if you\u0026rsquo;re sharing them. The less software that is installed, the fewer security vulnerabilities there will be. Making your images as small as possible can greatly reduce the burden on the rest of your infrastructure.  ",
        "source":"\n{{\u003cdescription\u003e}}\nWhen it comes to Docker containers, the smaller, the better. Smaller containers are easier to work with, deploy faster, and tend to have fewer security vulnerabilities.\n{{\u003c/description\u003e}}\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/docker-logo.jpg\" alt=\"Docker Logo\"\u003e}}\n\n{{% aside %}}\nThis piece is part of a larger series on [Engineering for Site Reliability](/series/engineering-for-site-reliability/), specifically _Docker_.\n{{% /aside %}}\n\n## Big is Bad\n\nI worked at [WePay]({{\u003c wayback \"https://wepay.com\" \u003e}}) during the transition from a monolithic application in the datacenter to a series of microservices running in the cloud. I spent a lot of time working on the Vagrant-based CentOS development environment for the monolith, and also started maintaining a custom CentOS base image in Google Cloud.\n\nAs we were all learning about Docker, images, containers, and how it all worked together, the director of DevOps declared (unilaterally) that we should create Docker base images for the various languages we were using (PHP, Python, Java, Go), and they should all be built on a core CentOS 7 Docker image.\n\nNow, many parts of this make sense:\n\n1. Having a base disk image for our hosts that builds-in all of the shared functionality we needed.\n\n1. Having a base Docker image that every application referenced with `FROM` in their `Dockerfiles` which included shared patterns for logging and metrics.\n\n1. Having an optimized image for specific languages made it easier for developers using those languages to rapidly spin-up new application containers.\n\nBut there were also some major drawbacks to this approach.\n\n1. Developers wanted to run `composer install` and `pip install requirements.txt` from _inside the container_. This often required _development dependencies_ to be installed in the containers.\n\n1. One of our Java micro-service applications (CentOS 7 + Oracle Java + application code + development dependencies) clocked in at **1.8 GB**.\n\n1. Our build system was frequently buckling under the weight of caching and transferring large Docker images between its cluster and our Artifactory installation.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/fat-guy.jpg\" alt=\"Fat Guy eating a donut and cheese-whiz\"\u003e}}\n\nNow, some of this can be chalked up to learning a new technology. Some of these are growing pains that were incurred at the same time as chunking apart our monolithic PHP app into Java/Python/Golang microservices. Some of this was hubris by people who made unilateral decisions. But we'd made it to the cloud. We'd made it to microservices. And I'm sure that WePay's development practices have improved greatly over the last couple of years since I left.\n\n## Smaller is better\n\nIn my current gig, my team has gone all-in with Docker, the AWS cloud, Infrastructure-as-Code, CI/CD practices, and the SRE support model. I'll spend some time talking about these other topics in a future post, but I do want to talk about some process magic that makes it nearly effortless to deploy to Production multiple times per day with exceptionally little stress.\n\n### Use Alpine Linux\n\n[Alpine Linux]({{\u003c wayback \"https://alpinelinux.org\" \u003e}}) is the **5 MB** successor to [Busybox]({{\u003c wayback \"https://www.busybox.net\" \u003e}}), which provides a few additional tools to Busybox’s **2 MB** image size.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/alpine.png\" alt=\"Alpine Linux size compared to other Docker images.\"\u003e}}\n\nGenerally speaking, **you should always use Alpine Linux**.\n\nI use the word \"generally\" because there are certain exceptions to this (otherwise) strong recommendation. The most important of which is that while larger Linux distributions which use the GNU’s [glibc]({{\u003c wayback \"https://www.gnu.org/software/libc/\" \u003e}}) library for the C Standard Library implementation, Alpine, Busybox, and others use a different library called [musl]({{\u003c wayback \"https://musl-libc.org\" \u003e}}).\n\nYou can take a look at the [differences between musl and glibc]({{\u003c wayback \"https://wiki.musl-libc.org/functional-differences-from-glibc.html\" \u003e}}), but the part that matters to you is that there is _some_ software that exists which depends on the non-standard parts of glibc that haven't been implemented in musl yet. What this means, practically speaking, are that things like the [`%P` marker for `strftime()` doesn't work as documented]({{\u003c wayback \"https://bugs.php.net/74982\" \u003e}}).\n\n### Learn to love the layer cache\n\nDocker images use _layers_ to overlay newer changes over previous changes using a technology called [UnionFS]({{\u003c wayback \"https://en.wikipedia.org/wiki/UnionFS\" \u003e}}). This works similarly to Git, where all of the changes that ever happened are still inside the repository, but when you pull the `master` branch, you're pulling down dozens (or _hundreds_, or _thousands_) of layers that all need to resolve into the current state of the branch.\n\nWith Docker, each of these layers is introduced by the [`RUN` statement]({{\u003c wayback \"https://docs.docker.com/engine/reference/builder/#run\" \u003e}}) inside a `Dockerfile`.\n\n```Dockerfile\nFROM nginx:1.15.1-alpine\n\nENV RUNTIME_DEPS ca-certificates curl\n\nRUN echo \"http://dl-cdn.alpinelinux.org/alpine/v3.7/main\" \u003e\u003e /etc/apk/repositories\nRUN apk upgrade --no-cache --update\nRUN apk add --no-cache --virtual .runtime-deps $RUNTIME_DEPS\nRUN chmod -Rf 0777 /var/log\n\n...\n```\n\nIf a change is made to an earlier layer, then the layer cache is invalidated for all of the later layers, and those later layers need to be rebuilt. (Because of this, it's always a good idea to put _infrequently_ changed commands first, and _more frequently_ changed commands last.)\n\nUnfortunately, many people (including myself) read that Docker image layers have filesize overhead built into them. In order to make your containers smaller, you should combine all of your commands into a single `RUN` statement. The side effect is that any time you need to change _anything_ inside that `RUN` statement, Docker needs to rebuild everything from scratch — since it's all in the same layer (which changed).\n\n```Dockerfile\nFROM nginx:1.15.1-alpine\n\nENV RUNTIME_DEPS ca-certificates curl\n\nRUN echo \"http://dl-cdn.alpinelinux.org/alpine/v3.7/main\" \u003e\u003e /etc/apk/repositories \u0026\u0026 \\\n    apk upgrade --no-cache --update \u0026\u0026 \\\n    apk add --no-cache --virtual .runtime-deps $RUNTIME_DEPS \u0026\u0026 \\\n    chmod -Rf 0777 /var/log\n\n...\n```\n\nBy leveraging the `RUN` statement as it was intended, you get to take advantage of faster re-build times by leveraging the _layer cache_. This means that any layers (e.g., `RUN` statements) which haven't changed since the last build do not need to be built again!\n\nYes, your _development_ Docker image may be a little larger, but we will address this later in this post.\n\n### Installed dependencies should be runtime-only\n\nThis is the one that kills me the most because it can be so wasteful, and it stems from not understanding how to use the tools in your toolbox.\n\nFirstly, use a [`.dockerignore` file]({{\u003c wayback \"https://docs.docker.com/engine/reference/builder/#dockerignore-file\" \u003e}}). Again, this is very similar to how a `.gitignore` file works — you don't need everything you use for development to end up inside your Docker image, so use `.dockerignore` to avoid development dependencies.\n\nYou never need your `.git/` directory to be copied into a Docker image. Once you've resolved your application dependencies, you also don't need your `composer.json`, `package.json`, `requirements.txt`, or other package manager definitions in there. You only need your vendored code. (Even then, you don't need the tests for the vendored code either, most of the time. You should ignore those as well.)\n\nSome dependencies need to build binaries for the OS they're running inside of. For example, Node.js apps often rely on _Oniguruma_. Many Python applications rely on _MySQLdb_. Both of these require that you install compilation tools and compile them on the OS that they run in.\n\nSome companies solve this problem by _installing GCC inside the Docker image_.\n\n{{\u003cfullimage src=\"https://cdn.ryanparman.com/hugo/posts/2018/mcfly-confused.gif\" mp4=true alt=\"Marty McFly looking very confused.\"\u003e}}\n\nA better solution is to have _build-time_ and _run-time_ dependencies, wherein you uninstall the build-time dependencies once you're done with them.\n\nHere is an example of a PHP app that includes Redis support and installs the New Relic agent extension.\n\n```Dockerfile\nFROM php:7.2.8-fpm-alpine3.7\n\n# Needed at build-time, then can be uninstalled.\nENV BUILD_DEPS alpine-sdk coreutils wget git autoconf re2c\n\n# Should remain inside the container for runtime purposes.\nENV PERSISTENT_DEPS net-tools hiredis-dev gmp-dev\n\n# PHP extensions to install.\nENV INSTALL_EXTENSIONS gmp json opcache pdo pdo_mysql\n\n# New Relic values.\nENV NR_INSTALL_SILENT 1\nENV NR_VERSION 8.0.0.204\n\n# Update the packages in the container to their latest security patches.\nRUN apk upgrade --no-cache --update\n\n# Install your build-time and runtime dependencies.\n# Give these groups of dependencies names like `.build-deps`\n# and `.persistent-deps` that we can refer to later.\nRUN apk add --no-cache --virtual .build-deps $BUILD_DEPS\nRUN apk add --no-cache --virtual .persistent-deps $PERSISTENT_DEPS\n\n# Install the PHP extensions we need from the PHP repository.\n# https://github.com/php/php-src/tree/master/ext\nRUN docker-php-ext-install $INSTALL_EXTENSIONS\n\n# Install the New Relic agent extension for PHP.\nRUN wget -O /tmp/newrelic-php5.tar.gz https://download.newrelic.com/php_agent/archive/$NR_VERSION/newrelic-php5-$NR_VERSION-linux-musl.tar.gz\nRUN tar -zxvf /tmp/newrelic-php5.tar.gz -C /usr/local/lib\nRUN /usr/local/lib/newrelic*/newrelic-install install\nRUN rm /usr/local/etc/php/conf.d/newrelic.ini\n\n# Install the phpiredis extension for PHP.\nRUN git clone https://github.com/nrk/phpiredis.git \u0026\u0026 cd phpiredis \u0026\u0026 phpize \u0026\u0026 ./configure --enable-phpiredis \u0026\u0026 make \u0026\u0026 make install\n\n# Uninstall the grouping of dependencies called `.build-deps`.\nRUN apk del .build-deps\n\n...\n```\n\n### Flattening your (base) images\n\nFlattening your images is an extra step that you can take to make your images as small as possible. This is particularly useful if you are building/providing _base_ images for other people to consume downstream.\n\nAs Thomas Uhrig [writes]({{\u003c wayback \"https://tuhrig.de/flatten-a-docker-container-or-image/\" \u003e}}):\n\n\u003e We can use this mechanism to flatten and shrink a Docker container. If we save an image to the disk, its whole history will be preserved, but if we export a container, its history gets lost and the resulting tarball will be much smaller.\n\n```bash\n# Launch the container from a Docker image\ndocker run \u003cimage\u003e --detach\n\n# Export the running container to a tarball\ndocker export \u003ccontainer\u003e \u003e /tmp/docker-image.tar\n \n# Import it back into Docker\ncat /tmp/docker-image.tar | docker import - php-fpm:without-layers\n```\n\nBy running a container and exporting the data as a tarball, you can remove all of the intermediate layers and history from the final image, removing filesize overhead and reducing the overall image size.\n\nAt the time of this writing, the latest version of [PHP is 7.2.8]({{\u003c wayback \"https://store.docker.com/images/php\" \u003e}}) (actually, 7.2.9 was cut yesterday, but the updated image hasn't been released yet), which builds on top of the [Alpine Linux 3.7]({{\u003c wayback \"https://store.docker.com/images/alpine\" \u003e}}) image.\n\nThe Alpine Linux image clocks in at just under **5 MB**. The PHP image adds a few layers, and brings things up to **78 MB**. So far, both of these are smaller than the base CentOS or Ubuntu images.\n\nOur application includes the New Relic agent for PHP, a few extensions, our application code, and our Composer `vendor` directory (without dev-dependencies).\n\n```bash\ncomposer install --prefer-dist --no-dev\n```\n\nWe _should_ remove things like tests from our `vendor` directory, but we haven't done that yet at the time of this writing. With all of our (wonderfully cached) layers, this brings the decompressed image size to **408 MB**.\n\nAfter stripping out the history and removing all of the individual layers from the image (via a process called _flattening_), our final _decompressed_ image size is a mere **197 MB** in size.\n\n```plain\n$ docker images\n\nREPOSITORY     TAG                   IMAGE ID       CREATED          SIZE\nalpine         3.7                   791c3e2ebfcb   5 weeks ago      4.2MB\nphp            7.2.7-fpm-alpine3.7   9cf17fea14c0   5 weeks ago      78.3MB\nphp-fpm        with-layers           94121f6a6537   29 seconds ago   408MB\nphp-fpm        without-layers        8468ea1ee874   4 seconds ago    197MB\n\n```\n\nWhen you push your image up to a Docker registry (e.g., Docker Hub, Amazon ECR, Google Container Registry, Quay.io, Artifactory), the images will be compressed. Our final Docker image, compressed-at-rest, is only **72 MB**.\n\nA small, 72 MB Docker image for our application is small and easy enough to push into our CI/CD pipeline in only a few seconds, and puts very little network or storage strain on our internal systems. It's fast to download into my local development environment, and every step of the development and build processes are automated.\n\n## Reduced security vulnerabilities\n\nOver my career, I've observed that engineers view the topic of \"security\" primarily through the lense of their job role.\n\n* Application engineers tend to view security as things like XSS vulnerabilities and SQL injections.\n\n* System engineers tend to view security as things like CVEs and intrusions.\n\n* Security engineers tend to see those things + TLS certificates + CIS Benchmarks + secrets management and rotation + user permissions + …\n\nIn this context, I'm referring primarily to _security vulnerabilties_ along the lines of [Heartbleed]({{\u003c wayback \"http://heartbleed.com\" \u003e}}), [ShellShock]({{\u003c wayback \"https://nvd.nist.gov/vuln/detail/CVE-2014-6271\" \u003e}}), and [httpoxy]({{\u003c wayback \"https://httpoxy.org\" \u003e}}). Because there is so little software installed by default, the _attack surface_ is substantially reduced — oftentimes to the point where there are zero known vulnerabilities anywhere in your application container.\n\n{{\u003cfullimage-noshadow src=\"https://cdn.ryanparman.com/hugo/posts/2018/heartbleed.png\" alt=\"Logo for the Heartbleed vulnerability.\" figure=\"Logo for the Heartbleed vulnerability.\"\u003e}}\n\nThis is entirely unheard of in CentOS, Ubuntu, and other larger distributions. As a matter of fact, when our application went live and we underwent review with the security team, they scanned our hosts and containers with zero unpatched vulnerabilities and thought that the scan was bad or their software was broken.\n\n## Conclusion\n\nThe most important things to take away from this are:\n\n1. Big Docker images are a bad thing.\n1. Use Alpine Linux. Seriously.\n1. Remove your build-time dependencies.\n1. Flatten your images if you're sharing them.\n1. The less software that is installed, the fewer security vulnerabilities there will be.\n1. Making your images as small as possible can greatly reduce the burden on the rest of your infrastructure.\n"},
    "links": {
        "prev": {"title": "Dear Nintendo, Part II", "permalink": "https://ryanparman.com/posts/2018/dear-nintendo-part-ii/"},
        "next": {"title": "Clueless Recruiters, Issue #8", "permalink": "https://ryanparman.com/posts/2018/clueless-recruiters-issue-8/"},
        "ignore": "me"
    }
}

            
        ]
    }
}
